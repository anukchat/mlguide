
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Summarizations</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/intro.css?v=adbe4504" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=2a9655cd" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-GJG3T4ZRZH"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-GJG3T4ZRZH');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-GJG3T4ZRZH');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/genai/langchain/projects/1_Summarizations';</script>
    <script src="../../../../_static/subscription_overlay.js?v=2e74803e"></script>
    <link rel="canonical" href="https://mlguide.in/content/genai/langchain/projects/1_Summarizations.html" />
    <link rel="icon" href="../../../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" /> 
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../../resources/blogs/atom.xml"
  title="Blog"
/>
  
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/MLGuide_logo_nb.png" class="logo__image only-light" alt=" - Home"/>
    <img src="../../../../_static/MLGuide_logo_nb.png" class="logo__image only-dark pst-js-only" alt=" - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../python/python_toc.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../python/1_installation.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/2_syntax_and_symantics.html">Syntax &amp; Symantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/3_functions_and_modules.html">Functions &amp; Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/4_Object_Oriented.html">Object Oriented Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/5_Exceptions_Handling.html">Exceptions Handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/6_Handling_Files.html">Handling Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/7_Datetime_Operations.html">Datetime Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/8_advanced.html">Advanced Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/conceptual_topics.html">Interpreter vs Compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../statistics/statistics-101.html">Statistics</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../mathematics/mathematics_toc.html">Mathematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../mathematics/linear-algebra_vectors.html">Vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mathematics/linear-algebra_matrices.html">Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mathematics/dissimilarity_measures.html">Similarity measure</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../analytics/intro_analytics.html">Data analytics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../analytics/numpy/numpy_toc.html">Numpy</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/numpy/001_Python_NumPy.html">NumPy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/numpy/Python_Numpy_Exercises_with_hints.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../analytics/pandas/pandas_toc.html">Pandas</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/pandas/001_Python_Pandas_DataFrame.html">Pandas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/pandas/002_Pandas_HowTos.html">How To's</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/pandas/003_Pandas_Exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../analytics/matplotlib/matplotlib_toc.html">Matplotlib</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/matplotlib/001_Python_Matplotlib.html">Matplotlib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/matplotlib/003_Python_Matplotlib_Exercises.html">Exercises</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ai/Introduction_to_ml.html">Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/classicml/concepts/01_Introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/classicml/concepts/000_Data_Exploration.html">Exploratory Data Analysis</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../ai/classicml/concepts/001_Data_Preparation.html">Data Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/classicml/concepts/002_Regression.html">Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/classicml/concepts/003_Classification.html">Classfication</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../ai/classicml/concepts/004_Clustering.html">Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/classicml/concepts/005_Evaluation.html">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/classicml/concepts/006_Advanced.html">K-Fold Cross Validation</a></li>


<li class="toctree-l2"><a class="reference internal" href="../../../ai/classicml/concepts/007_Dimensionality_Reduction.html">Dimensionality Reduction</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ai/neural/neural_toc.html">Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/neural/concepts/001_Introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/neural/concepts/002_Backpropogation.html">Backpropogation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/neural/concepts/003_Activations.html">Activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/neural/concepts/004_Optimization.html">Optimizations</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../ai/neural/concepts/pytorch/pytorch_toc.html">Pytorch</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ai/neural/concepts/pytorch/00_pytorch_fundamentals.html">Fundamentals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ai/neural/concepts/pytorch/01_pytorch_workflow.html">Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ai/neural/concepts/pytorch/02_pytorch_classification.html">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ai/neural/concepts/pytorch/03_pytorch_computer_vision.html">Computer Vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ai/neural/concepts/pytorch/04_pytorch_custom_datasets.html">Custom Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ai/neural/concepts/pytorch/06_pytorch_transfer_learning.html">Transfer Learning</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../ai/nlp/nlp_intro.html">Natural Language Processing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/001_traditional_nlp.html">Word Vectors &amp; Dependency Parsing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/002_embeddings.html">Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/003_ngram_cnn.html">N Gram using CNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/004_word2vec.html">Word2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/005_language_model_basic.html">Neural Language Model</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/006_language_model_rnn.html">Recurrent Neural Network (RNN)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/007_encoder_decoder.html">Encoder Decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/008_attention.html">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/009_transformer.html">Transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/010_llm_tasks.html">Language Modelling Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ai/nlp/concepts/011_appendix.html">Appendix</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../introduction.html">Generative AI</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../prompt-engineering/intro.html">Prompt Engineering</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../prompt-engineering/basic_prompting.html">Basic Prompting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../prompt-engineering/advance_prompts.html">Advanced Prompting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../prompt-engineering/prompts-applications.html">Prompts Applications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../prompt-engineering/prompts-adversarial.html">Prompts Adversarial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../prompt-engineering/prompts-reliability.html">Reliability</a></li>



</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../intro.html">Langchain</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../01_LangChain_Fundamentals.html">Langchain Cookbook 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_LangChain_Use_Cases.html">Langchain Cookbook 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="project_toc.html">Projects</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../RAG/intro.html">RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../agents/intro.html">Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../llm-recipes/intro.html">LLM Recipes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../evaluations/intro.html">Evaluations</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../resources/blogs/blogs_toc.html">Blogs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/courses/courses_toc.html">Courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/books/books_toc.html">Books</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/github/awesome-repos.html">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/readings/articles.html">News</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/readings/papers_toc.html">Research papers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../intro_me.html">About me</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/anukchat/mlguide/main?urlpath=lab/tree/content/genai/langchain/projects/1_Summarizations.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/anukchat/mlguide/blob/main/content/genai/langchain/projects/1_Summarizations.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/content/genai/langchain/projects/1_Summarizations.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Summarizations</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#levels-of-summarization-novice-to-expert">5 Levels Of Summarization: Novice to Expert</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-1-basic-prompt-summarize-a-couple-sentences">Level 1: Basic Prompt - Summarize a couple sentences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-2-prompt-templates-summarize-a-couple-paragraphs">Level 2: Prompt Templates - Summarize a couple paragraphs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-3-map-reduce-summarize-a-couple-pages-multiple-pages">Level 3: Map Reduce - Summarize a couple pages multiple pages</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-4-best-representation-vectors-summarize-an-entire-book">Level 4: Best Representation Vectors - Summarize an entire book</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-5-agents-summarize-an-unknown-amount-of-text">Level 5: Agents - Summarize an unknown amount of text</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-llms-to-summarize-personal-research">Using LLMs To Summarize Personal Research</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pulling-data-from-twitter">Pulling Data From Twitter</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pulling-data-from-websites">Pulling Data From Websites</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pulling-data-from-youtube">Pulling Data From YouTube</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                   <section class="tex2jax_ignore mathjax_ignore" id="summarizations">
<h1>Summarizations<a class="headerlink" href="#summarizations" title="Link to this heading">#</a></h1>
<p>LLM-based summarization involves using LLMs to generate concise versions of longer texts while retaining key information and context. The model analyzes the input, identifies important points, and rephrases the content into a shorter summary.</p>
<p>There are two main types:</p>
<p><strong>Extractive Summarization:</strong> Selects and extracts key sentences directly from the source.</p>
<p><strong>Abstractive Summarization</strong>: Rewrites the content in a new way, generating novel sentences that capture the main ideas.
LLM-based summarization is useful for simplifying complex documents, news articles, or reports.</p>
<section id="levels-of-summarization-novice-to-expert">
<h2>5 Levels Of Summarization: Novice to Expert<a class="headerlink" href="#levels-of-summarization-novice-to-expert" title="Link to this heading">#</a></h2>
<p>Summarization is a fundamental building block of many LLM tasks. You’ll frequently run into use cases where you would like to distill a large body of text into a succinct set of points.</p>
<p>Depending on the length of the text you’d like to summarize, you have different summarization methods to choose from.</p>
<p>We’re going to run through 5 methods for summarization that start with Novice and end up expert. These aren’t the only options, feel free to make up your own. If you find another one you like please share it with the community.</p>
<p><strong>5 Levels Of Summarization:</strong></p>
<ol class="arabic simple">
<li><p><strong>Summarize a couple sentences</strong> - Basic Prompt</p></li>
<li><p><strong>Summarize a couple paragraphs</strong> - Prompt Templates</p></li>
<li><p><strong>Summarize a couple pages</strong> - Map Reduce</p></li>
<li><p><strong>Summarize an entire book</strong> - Best Representation Vectors</p></li>
<li><p><strong>Summarize an unknown amount of text</strong> - Agents</p></li>
</ol>
<p>First let’s import our OpenAI API Key</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Unzip data folder</span>

<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="s1">&#39;../../data.zip&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">load_dotenv</span><span class="p">()</span>

<span class="n">openai_api_key</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;OPENAI_API_KEY&#39;</span><span class="p">,</span> <span class="s1">&#39;YourAPIKey&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="level-1-basic-prompt-summarize-a-couple-sentences">
<h3>Level 1: Basic Prompt - Summarize a couple sentences<a class="headerlink" href="#level-1-basic-prompt-summarize-a-couple-sentences" title="Link to this heading">#</a></h3>
<p>If you just have a few sentences you want to one-off summarize you can use a simple prompt and copy and paste your text.</p>
<p>This method isn’t scalable and only practical for a few use cases…the perfect level #1!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">OpenAI</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">openai_api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The important part is to provide instructions for the LLM to know what to do. In thise case I’m telling the model I want a summary of the text below</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Please provide a summary of the following text</span>

<span class="s2">TEXT:</span>
<span class="s2">Philosophy (from Greek: φιλοσοφία, philosophia, &#39;love of wisdom&#39;) </span><span class="se">\</span>
<span class="s2">is the systematized study of general and fundamental questions, </span><span class="se">\</span>
<span class="s2">such as those about existence, reason, knowledge, values, mind, and language. </span><span class="se">\</span>
<span class="s2">Some sources claim the term was coined by Pythagoras (c. 570 – c. 495 BCE), </span><span class="se">\</span>
<span class="s2">although this theory is disputed by some. Philosophical methods include questioning, </span><span class="se">\</span>
<span class="s2">critical discussion, rational argument, and systematic presentation.</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_tokens</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">get_num_tokens</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Our prompt has </span><span class="si">{</span><span class="n">num_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Our prompt has 121 tokens
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">llm</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Philosophy is a systematized study of general and fundamental questions about existence, reason, knowledge, values, mind, and language. It is believed to have been coined by Pythagoras, and its methods include questioning, critical discussion, rational argument, and systematic presentation.
</pre></div>
</div>
</div>
</div>
<p>Woof 🐶, that summary is still hard to understand. Let me add to my instructions so that the output is easier to understand. I’ll tell it to explain it to me like a 5 year old.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Please provide a summary of the following text.</span>
<span class="s2">Please provide your output in a manner that a 5 year old would understand</span>

<span class="s2">TEXT:</span>
<span class="s2">Philosophy (from Greek: φιλοσοφία, philosophia, &#39;love of wisdom&#39;) </span><span class="se">\</span>
<span class="s2">is the systematized study of general and fundamental questions, </span><span class="se">\</span>
<span class="s2">such as those about existence, reason, knowledge, values, mind, and language. </span><span class="se">\</span>
<span class="s2">Some sources claim the term was coined by Pythagoras (c. 570 – c. 495 BCE), </span><span class="se">\</span>
<span class="s2">although this theory is disputed by some. Philosophical methods include questioning, </span><span class="se">\</span>
<span class="s2">critical discussion, rational argument, and systematic presentation.</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_tokens</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">get_num_tokens</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Our prompt has </span><span class="si">{</span><span class="n">num_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Our prompt has 137 tokens
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">llm</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Philosophy is about asking questions and trying to figure out the answers. It is about thinking about things like existence, knowledge, and values. People have been doing this for a very long time, and it is still done today.
</pre></div>
</div>
</div>
</div>
<p>Nice! That’s much better, but let’s look at something we can automate a bit more</p>
</section>
<section id="level-2-prompt-templates-summarize-a-couple-paragraphs">
<h3>Level 2: Prompt Templates - Summarize a couple paragraphs<a class="headerlink" href="#level-2-prompt-templates-summarize-a-couple-paragraphs" title="Link to this heading">#</a></h3>
<p>Prompt templates are a great way to dynamically place text within your prompts. They are like <a class="reference external" href="https://realpython.com/python-f-strings/">python f-strings</a> but specialized for working with language models.</p>
<p>We’re going to look at 2 short Paul Graham essays</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">import</span> <span class="nn">os</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">paul_graham_essays</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;../data/PaulGrahamEssaySmall/getideas.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;../data/PaulGrahamEssaySmall/noob.txt&#39;</span><span class="p">]</span>

<span class="n">essays</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">paul_graham_essays</span><span class="p">:</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">essays</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s print out a preview of the essays to see what they look like</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">essay</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">essays</span><span class="p">):</span>
    <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Essay #</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">essay</span><span class="p">[:</span><span class="mi">300</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Essay #1: January 2023(Someone fed my essays into GPT to make something that could answer
questions based on them, then asked it where good ideas come from.  The
answer was ok, but not what I would have said. This is what I would have said.)The way to get new ideas is to notice anomalies: what seems strange,


Essay #2: January 2020When I was young, I thought old people had everything figured out.
Now that I&#39;m old, I know this isn&#39;t true.I constantly feel like a noob. It seems like I&#39;m always talking to
some startup working in a new field I know nothing about, or reading
a book about a topic I don&#39;t understand well
</pre></div>
</div>
</div>
</div>
<p>Next let’s create a prompt template which will hold our instructions and a placeholder for the essay. In this example I only want a 1 sentence summary to come back</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Please write a one sentence summary of the following text:</span>

<span class="si">{essay}</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;essay&quot;</span><span class="p">],</span>
    <span class="n">template</span><span class="o">=</span><span class="n">template</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then let’s loop through the 2 essays and pass them to our LLM. I’m applying .strip() on the summaries to remove the white space on the front and back of the output</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">essay</span> <span class="ow">in</span> <span class="n">essays</span><span class="p">:</span>
    <span class="n">summary_prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">essay</span><span class="o">=</span><span class="n">essay</span><span class="p">)</span>
    
    <span class="n">num_tokens</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">get_num_tokens</span><span class="p">(</span><span class="n">summary_prompt</span><span class="p">)</span>
    <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;This prompt + essay has </span><span class="si">{</span><span class="n">num_tokens</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
    
    <span class="n">summary</span> <span class="o">=</span> <span class="n">llm</span><span class="p">(</span><span class="n">summary_prompt</span><span class="p">)</span>
    
    <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Summary: </span><span class="si">{</span><span class="n">summary</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>This prompt + essay has 205 tokens
Summary: Exploring anomalies at the frontiers of knowledge is the best way to generate new ideas.


This prompt + essay has 500 tokens
Summary: This text explores the idea that feeling like a &quot;noob&quot; is actually beneficial, as it is inversely correlated with actual ignorance and encourages us to discover new things.
</pre></div>
</div>
</div>
</div>
</section>
<section id="level-3-map-reduce-summarize-a-couple-pages-multiple-pages">
<h3>Level 3: Map Reduce - Summarize a couple pages multiple pages<a class="headerlink" href="#level-3-map-reduce-summarize-a-couple-pages-multiple-pages" title="Link to this heading">#</a></h3>
<p>If you have multiple pages you’d like to summarize, you’ll likely run into a token limit. Token limits won’t always be a problem, but it is good to know how to handle them if you run into the issue.</p>
<p>The chain type “Map Reduce” is a method that helps with this. You first generate a summary of smaller chunks (that fit within the token limit) and then you get a summary of the summaries.\</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.chains.summarize</span> <span class="kn">import</span> <span class="n">load_summarize_chain</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">paul_graham_essay</span> <span class="o">=</span> <span class="s1">&#39;../data/PaulGrahamEssays/startupideas.txt&#39;</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">paul_graham_essay</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">essay</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see how many tokens are in this essay</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span><span class="o">.</span><span class="n">get_num_tokens</span><span class="p">(</span><span class="n">essay</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>9565
</pre></div>
</div>
</div>
</div>
<p>That’s too many, let’s split our text up into chunks so they fit into the prompt limit. I’m going a chunk size of 10,000 characters.</p>
<blockquote>
<div><p>You can think of tokens as pieces of words used for natural language processing. For English text, <strong>1 token is approximately 4 characters</strong> or 0.75 words. As a point of reference, the collected works of Shakespeare are about 900,000 words or 1.2M tokens.</p>
</div></blockquote>
<p>This means the number of tokens we should expect is 10,000 / 4 = ~2,500 token chunks. But this will vary, each body of text/code will be different</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">separators</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">],</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">essay</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_docs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>

<span class="n">num_tokens_first_doc</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">get_num_tokens</span><span class="p">(</span><span class="n">docs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Now we have </span><span class="si">{</span><span class="n">num_docs</span><span class="si">}</span><span class="s2"> documents and the first one has </span><span class="si">{</span><span class="n">num_tokens_first_doc</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Now we have 5 documents and the first one has 2086 tokens
</pre></div>
</div>
</div>
</div>
<p>Great, assuming that number of tokens is consistent in the other docs we should be good to go. Let’s use LangChain’s <a class="reference external" href="https://python.langchain.com/en/latest/use_cases/summarization.html">load_summarize_chain</a> to do the <code class="docutils literal notranslate"><span class="pre">map_reducing</span></code> for us. We first need to initialize our chain</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_chain</span> <span class="o">=</span> <span class="n">load_summarize_chain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> <span class="n">chain_type</span><span class="o">=</span><span class="s1">&#39;map_reduce&#39;</span><span class="p">,</span>
<span class="c1">#                                      verbose=True # Set verbose=True if you want to see the prompts being used</span>
                                    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now actually run it</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">summary_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39; This article provides strategies for coming up with startup ideas on demand, such as looking in areas of expertise, talking to people about their needs, and looking for waves and gaps in the market. It also discusses the need for users to have sufficient activation energy to start using a product, and how this varies depending on the product. It looks at the difficulty of switching paths in life as one gets older, and how colleges can help students start startups. Finally, it looks at the importance of focusing on users rather than competitors, and how Steve Wozniak solved his own problems.&#39;
</pre></div>
</div>
</div>
</div>
<p>This summary is a great start, but I’m more of a bullet point person. I want to get my final output in bullet point form.</p>
<p>In order to do this I’m going to use custom promopts (like we did above) to instruct the model on what I want.</p>
<p>The map_prompt is going to stay the same (just showing it for clarity), but I’ll edit the combine_prompt.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">map_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Write a concise summary of the following:</span>
<span class="s2">&quot;</span><span class="si">{text}</span><span class="s2">&quot;</span>
<span class="s2">CONCISE SUMMARY:</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">map_prompt_template</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">map_prompt</span><span class="p">,</span> <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">combine_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Write a concise summary of the following text delimited by triple backquotes.</span>
<span class="s2">Return your response in bullet points which covers the key points of the text.</span>
<span class="s2">```</span><span class="si">{text}</span><span class="s2">```</span>
<span class="s2">BULLET POINT SUMMARY:</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">combine_prompt_template</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">combine_prompt</span><span class="p">,</span> <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summary_chain</span> <span class="o">=</span> <span class="n">load_summarize_chain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span>
                                     <span class="n">chain_type</span><span class="o">=</span><span class="s1">&#39;map_reduce&#39;</span><span class="p">,</span>
                                     <span class="n">map_prompt</span><span class="o">=</span><span class="n">map_prompt_template</span><span class="p">,</span>
                                     <span class="n">combine_prompt</span><span class="o">=</span><span class="n">combine_prompt_template</span><span class="p">,</span>
<span class="c1">#                                      verbose=True</span>
                                    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">summary_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>- Y Combinator suggests that the best startup ideas come from looking for problems, preferably ones that the founders have themselves.
- Good ideas should appeal to a small number of people who need it urgently.
- To find startup ideas, one should look for things that seem to be missing and be prepared to question the status quo.
- College students should use their college experience to prepare themselves for the future and build things with other students.
- Tricks for coming up with startup ideas on demand include looking in areas of expertise, talking to people about their needs, and looking for waves and gaps in the market.
- Sam Altman points out that taking the time to come up with an idea is a better strategy than most founders are willing to put in the time for.
- Paul Buchheit suggests that trying to sell something bad can lead to better ideas.
</pre></div>
</div>
</div>
</div>
</section>
<section id="level-4-best-representation-vectors-summarize-an-entire-book">
<h3>Level 4: Best Representation Vectors - Summarize an entire book<a class="headerlink" href="#level-4-best-representation-vectors-summarize-an-entire-book" title="Link to this heading">#</a></h3>
<p>In the above method we pass the entire document (all 9.5K tokens of it) to the LLM. But what if you have more tokens than that?</p>
<p>What if you had a book you wanted to summarize? Let’s load one up, we’re going to load <a class="reference external" href="https://www.amazon.com/Into-Thin-Air-Personal-Disaster/dp/0385494785">Into Thin Air</a> about the 1996 Everest Disaster</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">PyPDFLoader</span>

<span class="c1"># Load the book</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">PyPDFLoader</span><span class="p">(</span><span class="s2">&quot;../data/IntoThinAirBook.pdf&quot;</span><span class="p">)</span>
<span class="n">pages</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>

<span class="c1"># Cut out the open and closing parts</span>
<span class="n">pages</span> <span class="o">=</span> <span class="n">pages</span><span class="p">[</span><span class="mi">26</span><span class="p">:</span><span class="mi">277</span><span class="p">]</span>

<span class="c1"># Combine the pages, and replace the tabs with spaces</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="n">pages</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">+=</span> <span class="n">page</span><span class="o">.</span><span class="n">page_content</span>
    
<span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_tokens</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">get_num_tokens</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;This book has </span><span class="si">{</span><span class="n">num_tokens</span><span class="si">}</span><span class="s2"> tokens in it&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>This book has 139472 tokens in it
</pre></div>
</div>
</div>
</div>
<p>Wow, that’s over 100K tokens, even <a class="reference external" href="https://help.openai.com/en/articles/7127966-what-is-the-difference-between-the-gpt-4-models">GPT 32K</a> wouldn’t be able to handle that in one go. At <a class="reference external" href="https://help.openai.com/en/articles/7127956-how-much-does-gpt-4-cost">0.03 per 1K prompt tokens</a>, this would cost us $4.17 just for the prompt alone.</p>
<p>So how do we do this without going through all the tokens? Pick random chunks? Pick equally spaced chunks?</p>
<p><strong>Goal:</strong> Chunk your book then get embeddings of the chunks. Pick a subset of chunks which represent a wholistic but diverse view of the book. Or another way, is there a way to pick the top 10 passages that describe the book the best?</p>
<p>Once we have our chunks that represent the book then we can summarize those chunks and hopefully get a pretty good summary.</p>
<p>Keep in mind there are tools that would likely do this for you, and with token limits increasing this won’t be a problem for long. But if you want to do it from scratch this might help.</p>
<p>This is most definitely not the optimal answer, but it’s my take on it for now! If the <a class="reference external" href="https://scikit-learn.org/stable/modules/clustering.html">clustering</a> experts wanna help improve it that would be awesome.</p>
<p><strong>The BRV Steps:</strong></p>
<ol class="arabic simple">
<li><p>Load your book into a single text file</p></li>
<li><p>Split your text into large-ish chunks</p></li>
<li><p>Embed your chunks to get vectors</p></li>
<li><p>Cluster the vectors to see which are similar to each other and likely talk about the same parts of the book</p></li>
<li><p>Pick embeddings that represent the cluster the most (method: closest to each cluster centroid)</p></li>
<li><p>Summarize the documents that these embeddings represent</p></li>
</ol>
<p>Another way to phrase this process, “Which ~10 documents from this book represent most of the meaning? I want to build a summary off those.”</p>
<p>Note: There will be a bit of information loss, but show me a summary of a whole book that doesn’t have information loss ;)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Loaders</span>
<span class="kn">from</span> <span class="nn">langchain.schema</span> <span class="kn">import</span> <span class="n">Document</span>

<span class="c1"># Splitters</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>

<span class="c1"># Model</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="c1"># Embedding Support</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">FAISS</span>
<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>

<span class="c1"># Summarizer we&#39;ll use for Map Reduce</span>
<span class="kn">from</span> <span class="nn">langchain.chains.summarize</span> <span class="kn">import</span> <span class="n">load_summarize_chain</span>

<span class="c1"># Data Science</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/gregorykamradt/opt/anaconda3/lib/python3.9/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.7.2) is available. It&#39;s recommended that you update to the latest version using `pip install -U deeplake`.
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<p>I’m going to initialize two models, gpt-3.5 and gpt4. I’ll use gpt 3.5 for the first set of summaries to reduce cost and then gpt4 for the final pass which should hopefully increase the quality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">separators</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">],</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">3000</span><span class="p">)</span>

<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_documents</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Now our book is split up into </span><span class="si">{</span><span class="n">num_documents</span><span class="si">}</span><span class="s2"> documents&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Now our book is split up into 78 documents
</pre></div>
</div>
</div>
</div>
<p>Let’s get our embeddings of those 78 documents</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">OpenAIEmbeddings</span><span class="p">(</span><span class="n">openai_api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">)</span>

<span class="n">vectors</span> <span class="o">=</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">embed_documents</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s cluster our embeddings. There are a ton of clustering algorithms you can chose from. Please try a few out to see what works best for you!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assuming &#39;embeddings&#39; is a list or array of 1536-dimensional embeddings</span>

<span class="c1"># Choose the number of clusters, this can be adjusted based on the book&#39;s content.</span>
<span class="c1"># I played around and found ~10 was the best.</span>
<span class="c1"># Usually if you have 10 passages from a book you can tell what it&#39;s about</span>
<span class="n">num_clusters</span> <span class="o">=</span> <span class="mi">11</span>

<span class="c1"># Perform K-means clustering</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">num_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here are the clusters that were found. It’s interesting to see the progression of clusters throughout the book. This is expected because as the plot changes you’d expect different clusters to emerge due to different semantic meaning</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
</div>
</div>
<p>This is sweet, but whenever you have a clustering exercise, it’s hard <em>not</em> to graph them. Make sure you add colors.</p>
<p>We also need to do dimensionality reduction to reduce the vectors from 1536 dimensions to 2 (this is sloppy data science but we are working towards the 80% solution)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Taking out the warnings</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">simplefilter</span>

<span class="c1"># Filter out FutureWarnings</span>
<span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>

<span class="c1"># Perform t-SNE and reduce to 2 dimensions</span>
<span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">reduced_data_tsne</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>

<span class="c1"># Plot the reduced data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">reduced_data_tsne</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">reduced_data_tsne</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Dimension 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Dimension 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Book Embeddings Clustered&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Awesome, not perfect, but pretty good directionally. Now we need to get the vectors which are closest to the cluster centroids (the center).</p>
<p>The function below is a quick way to do that (w/ help from ChatGPT)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find the closest embeddings to the centroids</span>

<span class="c1"># Create an empty list that will hold your closest points</span>
<span class="n">closest_indices</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Loop through the number of clusters you have</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">):</span>
    
    <span class="c1"># Get the list of distances from that particular cluster center</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">vectors</span> <span class="o">-</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Find the list position of the closest one (using argmin to find the smallest distance)</span>
    <span class="n">closest_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
    
    <span class="c1"># Append that position to your closest indices list</span>
    <span class="n">closest_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">closest_index</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now sort them (so the chunks are processed in order)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">selected_indices</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">closest_indices</span><span class="p">)</span>
<span class="n">selected_indices</span>
</pre></div>
</div>
</div>
</div>
<p>It’s intersting to see which chunks pop up at most descriptive. How does your distribution look?</p>
<p>Let’s create our custom prompts. I’m going to use gpt4 (which has a bigger token limit) for the combine step so I’m asking for long summaries in the map step to reduce the information loss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">llm3</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">openai_api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">,</span>
                 <span class="n">max_tokens</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">model</span><span class="o">=</span><span class="s1">&#39;gpt-3.5-turbo&#39;</span>
                <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">map_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">You will be given a single passage of a book. This section will be enclosed in triple backticks (```)</span>
<span class="s2">Your goal is to give a summary of this section so that a reader will have a full understanding of what happened.</span>
<span class="s2">Your response should be at least three paragraphs and fully encompass what was said in the passage.</span>

<span class="s2">```</span><span class="si">{text}</span><span class="s2">```</span>
<span class="s2">FULL SUMMARY:</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">map_prompt_template</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">map_prompt</span><span class="p">,</span> <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>I kept getting a timeout errors so I’m actually going to do this map reduce manually</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">map_chain</span> <span class="o">=</span> <span class="n">load_summarize_chain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm3</span><span class="p">,</span>
                             <span class="n">chain_type</span><span class="o">=</span><span class="s2">&quot;stuff&quot;</span><span class="p">,</span>
                             <span class="n">prompt</span><span class="o">=</span><span class="n">map_prompt_template</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then go get your docs which the top vectors represented.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">selected_docs</span> <span class="o">=</span> <span class="p">[</span><span class="n">docs</span><span class="p">[</span><span class="n">doc</span><span class="p">]</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">selected_indices</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s loop through our selected docs and get a good summary for each chunk. We’ll store the summary in a list.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make an empty list to hold your summaries</span>
<span class="n">summary_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Loop through a range of the lenght of your selected docs</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">doc</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">selected_docs</span><span class="p">):</span>
    
    <span class="c1"># Go get a summary of the chunk</span>
    <span class="n">chunk_summary</span> <span class="o">=</span> <span class="n">map_chain</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">doc</span><span class="p">])</span>
    
    <span class="c1"># Append that summary to your list</span>
    <span class="n">summary_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk_summary</span><span class="p">)</span>
    
    <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Summary #</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> (chunk #</span><span class="si">{</span><span class="n">selected_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">) - Preview: </span><span class="si">{</span><span class="n">chunk_summary</span><span class="p">[:</span><span class="mi">250</span><span class="p">]</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Great, now that we have our list of summaries, let’s get a summary of the summaries</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">summaries</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">summary_list</span><span class="p">)</span>

<span class="c1"># Convert it back to a document</span>
<span class="n">summaries</span> <span class="o">=</span> <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="n">summaries</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Your total summary has </span><span class="si">{</span><span class="n">llm</span><span class="o">.</span><span class="n">get_num_tokens</span><span class="p">(</span><span class="n">summaries</span><span class="o">.</span><span class="n">page_content</span><span class="p">)</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">llm4</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">openai_api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">,</span>
                 <span class="n">max_tokens</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span>
                 <span class="n">model</span><span class="o">=</span><span class="s1">&#39;gpt-4&#39;</span><span class="p">,</span>
                 <span class="n">request_timeout</span><span class="o">=</span><span class="mi">120</span>
                <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">combine_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">You will be given a series of summaries from a book. The summaries will be enclosed in triple backticks (```)</span>
<span class="s2">Your goal is to give a verbose summary of what happened in the story.</span>
<span class="s2">The reader should be able to grasp what happened in the book.</span>

<span class="s2">```</span><span class="si">{text}</span><span class="s2">```</span>
<span class="s2">VERBOSE SUMMARY:</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">combine_prompt_template</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">combine_prompt</span><span class="p">,</span> <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reduce_chain</span> <span class="o">=</span> <span class="n">load_summarize_chain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">llm4</span><span class="p">,</span>
                             <span class="n">chain_type</span><span class="o">=</span><span class="s2">&quot;stuff&quot;</span><span class="p">,</span>
                             <span class="n">prompt</span><span class="o">=</span><span class="n">combine_prompt_template</span><span class="p">,</span>
<span class="c1">#                              verbose=True # Set this to true if you want to see the inner workings</span>
                                   <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Run! Note this will take a while</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">reduce_chain</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">summaries</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Wow that was a long process, but you get the gist, hopefully we’ll see some library abstractions in the coming months that do this automatically for us! Let me know what you think on <a class="reference external" href="https://twitter.com/GregKamradt">Twitter</a></p>
</section>
<section id="level-5-agents-summarize-an-unknown-amount-of-text">
<h3>Level 5: Agents - Summarize an unknown amount of text<a class="headerlink" href="#level-5-agents-summarize-an-unknown-amount-of-text" title="Link to this heading">#</a></h3>
<p>What if you have an unknown amount of text you need to summarize? This may be a verticalize use case (like law or medical) where more research is required as you uncover the first pieces of information.</p>
<p>We’re going to use agents below, this is still a very actively developed area and should be handled with care. Future agents will be able to handle a lot more complicated tasks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">initialize_agent</span><span class="p">,</span> <span class="n">Tool</span>
<span class="kn">from</span> <span class="nn">langchain.utilities</span> <span class="kn">import</span> <span class="n">WikipediaAPIWrapper</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;gpt-4&#39;</span><span class="p">,</span> <span class="n">openai_api_key</span><span class="o">=</span><span class="n">openai_api_key</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We’re going to use the Wiki search tool and research multiple topics</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wikipedia</span> <span class="o">=</span> <span class="n">WikipediaAPIWrapper</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s define our toolkit, in this case it’s just one tool</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tools</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">Tool</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Wikipedia&quot;</span><span class="p">,</span>
        <span class="n">func</span><span class="o">=</span><span class="n">wikipedia</span><span class="o">.</span><span class="n">run</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Useful for when you need to get information from wikipedia about a single topic&quot;</span>
    <span class="p">),</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Init our agent</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">agent_executor</span> <span class="o">=</span> <span class="n">initialize_agent</span><span class="p">(</span><span class="n">tools</span><span class="p">,</span> <span class="n">llm</span><span class="p">,</span> <span class="n">agent</span><span class="o">=</span><span class="s1">&#39;zero-shot-react-description&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then let’s ask a question that will need multiple documents</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">agent_executor</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;Can you please provide a quick summary of Napoleon Bonaparte? </span><span class="se">\</span>
<span class="s2">                          Then do a separate search and tell me what the commonalities are with Serena Williams&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="using-llms-to-summarize-personal-research">
<h2>Using LLMs To Summarize Personal Research<a class="headerlink" href="#using-llms-to-summarize-personal-research" title="Link to this heading">#</a></h2>
<p>Our goal is to have LLM aid us in generating interview quetions for someone. I find that I’m constantly trying to ramp up to a person’s background and story when preparing to meet them.</p>
<p>There is a ton of awesome resources about a person online we can use</p>
<ul class="simple">
<li><p>Twitter Profiles</p></li>
<li><p>Websites</p></li>
<li><p>Other Interviews (YouTube or Text)</p></li>
</ul>
<p>Let’s bring all these together by first pulling the information and then generating questions or bullet points we can use as preparation.</p>
<p>First let’s import our packages! We’ll be using LangChain to help us interact with OpenAI</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Unzip data folder</span>

<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="s1">&#39;../../data.zip&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># LLMs</span>
<span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">langchain.chains.summarize</span> <span class="kn">import</span> <span class="n">load_summarize_chain</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="c1"># Twitter</span>
<span class="kn">import</span> <span class="nn">tweepy</span>

<span class="c1"># Scraping</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">markdownify</span> <span class="kn">import</span> <span class="n">markdownify</span> <span class="k">as</span> <span class="n">md</span>

<span class="c1"># YouTube</span>
<span class="kn">from</span> <span class="nn">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">YoutubeLoader</span>
<span class="c1"># !pip install youtube-transcript-api</span>

<span class="c1"># Environment Variables</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>

<span class="n">load_dotenv</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>You’ll need a few API keys to complete the script below. It’s modular so if you don’t want to pull from Twitter feel free to leave those blank</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">TWITTER_API_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;TWITTER_API_KEY&#39;</span><span class="p">,</span> <span class="s1">&#39;YourAPIKeyIfNotSet&#39;</span><span class="p">)</span>
<span class="n">TWITTER_API_SECRET</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;TWITTER_API_SECRET&#39;</span><span class="p">,</span> <span class="s1">&#39;YourAPIKeyIfNotSet&#39;</span><span class="p">)</span>
<span class="n">TWITTER_ACCESS_TOKEN</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;TWITTER_ACCESS_TOKEN&#39;</span><span class="p">,</span> <span class="s1">&#39;YourAPIKeyIfNotSet&#39;</span><span class="p">)</span>
<span class="n">TWITTER_ACCESS_TOKEN_SECRET</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;TWITTER_ACCESS_TOKEN_SECRET&#39;</span><span class="p">,</span> <span class="s1">&#39;YourAPIKeyIfNotSet&#39;</span><span class="p">)</span>
<span class="n">OPENAI_API_KEY</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;OPENAI_API_KEY&#39;</span><span class="p">,</span> <span class="s1">&#39;YourAPIKeyIfNotSet&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For this tutorial, let’s pretend we are going to be interviewing <a class="reference external" href="https://eladgil.com/">Elad Gil</a> since he has a bunch of content online</p>
<section id="pulling-data-from-twitter">
<h3>Pulling Data From Twitter<a class="headerlink" href="#pulling-data-from-twitter" title="Link to this heading">#</a></h3>
<p>Great, now let’s set up a function that will pull tweets for us. This will help us get current events that the user is talking about. I’m excluding replies since they usually don’t have a ton of high signal text from the user. This is the same code that was used in the <a class="reference external" href="https://youtu.be/yLWLDjT01q8">Twitter AI Bot tutorial</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_original_tweets</span><span class="p">(</span><span class="n">screen_name</span><span class="p">,</span> <span class="n">tweets_to_pull</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">tweets_to_return</span><span class="o">=</span><span class="mi">80</span><span class="p">):</span>
    
    <span class="c1"># Tweepy set up</span>
    <span class="n">auth</span> <span class="o">=</span> <span class="n">tweepy</span><span class="o">.</span><span class="n">OAuthHandler</span><span class="p">(</span><span class="n">TWITTER_API_KEY</span><span class="p">,</span> <span class="n">TWITTER_API_SECRET</span><span class="p">)</span>
    <span class="n">auth</span><span class="o">.</span><span class="n">set_access_token</span><span class="p">(</span><span class="n">TWITTER_ACCESS_TOKEN</span><span class="p">,</span> <span class="n">TWITTER_ACCESS_TOKEN_SECRET</span><span class="p">)</span>
    <span class="n">api</span> <span class="o">=</span> <span class="n">tweepy</span><span class="o">.</span><span class="n">API</span><span class="p">(</span><span class="n">auth</span><span class="p">)</span>

    <span class="c1"># Holder for the tweets you&#39;ll find</span>
    <span class="n">tweets</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="c1"># Go and pull the tweets</span>
    <span class="n">tweepy_results</span> <span class="o">=</span> <span class="n">tweepy</span><span class="o">.</span><span class="n">Cursor</span><span class="p">(</span><span class="n">api</span><span class="o">.</span><span class="n">user_timeline</span><span class="p">,</span>
                                   <span class="n">screen_name</span><span class="o">=</span><span class="n">screen_name</span><span class="p">,</span>
                                   <span class="n">tweet_mode</span><span class="o">=</span><span class="s1">&#39;extended&#39;</span><span class="p">,</span>
                                   <span class="n">exclude_replies</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">(</span><span class="n">tweets_to_pull</span><span class="p">)</span>
    
    <span class="c1"># Run through tweets and remove retweets and quote tweets so we can only look at a user&#39;s raw emotions</span>
    <span class="k">for</span> <span class="n">status</span> <span class="ow">in</span> <span class="n">tweepy_results</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">status</span><span class="p">,</span> <span class="s1">&#39;retweeted_status&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">status</span><span class="p">,</span> <span class="s1">&#39;quoted_status&#39;</span><span class="p">):</span>
            <span class="c1"># Skip if it&#39;s a retweet or quote tweet</span>
            <span class="k">continue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tweets</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s1">&#39;full_text&#39;</span><span class="p">:</span> <span class="n">status</span><span class="o">.</span><span class="n">full_text</span><span class="p">,</span> <span class="s1">&#39;likes&#39;</span><span class="p">:</span> <span class="n">status</span><span class="o">.</span><span class="n">favorite_count</span><span class="p">})</span>

    
    <span class="c1"># Sort the tweets by number of likes. This will help us short_list the top ones later</span>
    <span class="n">sorted_tweets</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">tweets</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s1">&#39;likes&#39;</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Get the text and drop the like count from the dictionary</span>
    <span class="n">full_text</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="s1">&#39;full_text&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">sorted_tweets</span><span class="p">][:</span><span class="n">tweets_to_return</span><span class="p">]</span>
    
    <span class="c1"># Convert the list of tweets into a string of tweets we can use in the prompt later</span>
    <span class="n">users_tweets</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">full_text</span><span class="p">)</span>
            
    <span class="k">return</span> <span class="n">users_tweets</span>
</pre></div>
</div>
</div>
</div>
<p>Ok cool, let’s try it out!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">user_tweets</span> <span class="o">=</span> <span class="n">get_original_tweets</span><span class="p">(</span><span class="s2">&quot;eladgil&quot;</span><span class="p">)</span>
<span class="nb">print</span> <span class="p">(</span><span class="n">user_tweets</span><span class="p">[:</span><span class="mi">300</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>More AI companies with sudden virality + paying customers should just bootstrap

0. Running co for cash may be best success

1. If it does scale, being profitable or near to it creates lot of options

2. it may not scale, or only work for a few months

3. Why get on the… https://t.co/Q9TRQo4yau

Som
</pre></div>
</div>
</div>
</div>
<p>Awesome, now we have a few tweets let’s move onto pulling data from a web page or two.</p>
</section>
<section id="pulling-data-from-websites">
<h3>Pulling Data From Websites<a class="headerlink" href="#pulling-data-from-websites" title="Link to this heading">#</a></h3>
<p>Let’s do two pages</p>
<ol class="arabic simple">
<li><p>His personal website which has his background - <a class="reference external" href="https://eladgil.com/">https://eladgil.com/</a></p></li>
<li><p>One of my favorite blog posts from him around AI defensibility &amp; moats - <a class="reference external" href="https://blog.eladgil.com/p/defensibility-and-competition">https://blog.eladgil.com/p/defensibility-and-competition</a></p></li>
</ol>
<p>First let’s create a function that will scrape a website for us.</p>
<p>We’ll do this by pulling the raw html, put it in a BeautifulSoup object, then convert that object to Markdown for better parsing</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">pull_from_website</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    
    <span class="c1"># Doing a try in case it doesn&#39;t work</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="c1"># In case it doesn&#39;t work</span>
        <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Whoops, error&quot;</span><span class="p">)</span>
        <span class="k">return</span>
    
    <span class="c1"># Put your response in a beautiful soup</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="s1">&#39;html.parser&#39;</span><span class="p">)</span>
    
    <span class="c1"># Get your text</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">get_text</span><span class="p">()</span>

    <span class="c1"># Convert your html to markdown. This reduces tokens and noise</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">md</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
     
    <span class="k">return</span> <span class="n">text</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># I&#39;m going to store my website data in a simple string.</span>
<span class="c1"># There is likely optimization to make this better but it&#39;s a solid 80% solution</span>

<span class="n">website_data</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
<span class="n">urls</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;https://eladgil.com/&quot;</span><span class="p">,</span> <span class="s2">&quot;https://blog.eladgil.com/p/defensibility-and-competition&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">pull_from_website</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
    
    <span class="n">website_data</span> <span class="o">+=</span> <span class="n">text</span>
</pre></div>
</div>
</div>
</div>
<p>Awesome, now that we have both of those data sources, let’s check out a sample</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="n">website_data</span><span class="p">[:</span><span class="mi">400</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Elad Gil




Welcome to Elad Gil&#39;s retro homepage!

 Who? I am a technology entrepreneur. LinkedIn profile is here.
What?
I am an investor or advisor to companies including Airbnb, Airtable, Anduril, Brex, Checkr, Coinbase, dbt Labs, Deel, Figma, Flexport, Gitlab, Gusto, Instacart, Navan, Notion, Opendoor, PagerDuty, Pinterest, Retool, Rippling, Samsara, Square, Stripe
I am involved with AI com
</pre></div>
</div>
</div>
</div>
<p>Awesome, to round us off, let’s get the information from a youtube video. YouTube has tons of data like Podcasts and interviews. This will be valuable for us to have.</p>
</section>
<section id="pulling-data-from-youtube">
<h3>Pulling Data From YouTube<a class="headerlink" href="#pulling-data-from-youtube" title="Link to this heading">#</a></h3>
<p>We’ll use LangChains YouTube loaders for this. It only works if there is a transcript on the YT video already, if there isn’t then we’ll move on. You could get the transcript via Whisper if you really wanted to, but that’s out of scope for today.</p>
<p>We’ll make a function we can use to loop through videos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pulling data from YouTube in text form</span>
<span class="k">def</span> <span class="nf">get_video_transcripts</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">YoutubeLoader</span><span class="o">.</span><span class="n">from_youtube_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">add_video_info</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">()</span>
    <span class="n">transcript</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">documents</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">transcript</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using a regular string to store the youtube transcript data</span>
<span class="c1"># Video selection will be important.</span>
<span class="c1"># Parsing interviews is a whole other can of worms so I&#39;m opting for one where Elad is mostly talking about himself</span>
<span class="n">video_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;https://www.youtube.com/watch?v=nglHX4B33_o&#39;</span><span class="p">]</span>
<span class="n">videos_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="k">for</span> <span class="n">video_url</span> <span class="ow">in</span> <span class="n">video_urls</span><span class="p">:</span>
    <span class="n">video_text</span> <span class="o">=</span> <span class="n">get_video_transcripts</span><span class="p">(</span><span class="n">video_url</span><span class="p">)</span>
    
    <span class="n">videos_text</span> <span class="o">+=</span> <span class="n">video_text</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at at sample from the video</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">video_text</span><span class="p">[:</span><span class="mi">300</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>I like to say that startups are an act of desperation and the desperation went out of the ecosystem over the last two or three years and we just had people showing up for the status and the money and now I think it&#39;s getting back to people who are doing it for a variety of reasons including the impa
</pre></div>
</div>
</div>
</div>
<p>Awesome now that we have all of our data, let’s combine it together into a single information block</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">user_information</span> <span class="o">=</span> <span class="n">user_tweets</span> <span class="o">+</span> <span class="n">website_data</span> <span class="o">+</span> <span class="n">video_text</span>
</pre></div>
</div>
</div>
</div>
<p>Our <code class="docutils literal notranslate"><span class="pre">user_information</span></code> variable is a big messy wall of text. Ideally we would clean this up more and try to increase the signal to noise ratio. However for this project we’ll just focus on the core use case of gathering data.</p>
<p>Next we’ll chunk our wall of text into pieces so we can do a map_reduce process on it. If you want learn more about techniques to split up your data check out my video on <a class="reference external" href="https://www.youtube.com/watch?v=f9_BWhCI4Zo">OpenAI Token Workarounds</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First we make our text splitter</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="n">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">20000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Then we split our user information into different documents</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="o">.</span><span class="n">create_documents</span><span class="p">([</span><span class="n">user_information</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s see how many documents we created</span>
<span class="nb">len</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3
</pre></div>
</div>
</div>
</div>
<p>Because we have a special requset for the LLM on our data, I want to make custom prompts. This will allow me to tinker with what data the LLM pulls out. I’ll use Langchain’s <code class="docutils literal notranslate"><span class="pre">load_summarize_chain</span></code> with custom prompts to do this. We aren’t making a summary, but rather just using <code class="docutils literal notranslate"><span class="pre">load_summarize_chain</span></code> for its easy mapreduce functionality.</p>
<p>First let’s make our custom map prompt. This is where we’ll instruction the LLM that it will pull out interview questoins and what makes a good question.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">map_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are a helpful AI bot that aids a user in research.</span>
<span class="s2">Below is information about a person named </span><span class="si">{persons_name}</span><span class="s2">.</span>
<span class="s2">Information will include tweets, interview transcripts, and blog posts about </span><span class="si">{persons_name}</span>
<span class="s2">Your goal is to generate interview questions that we can ask </span><span class="si">{persons_name}</span>
<span class="s2">Use specifics from the research when possible</span>

<span class="s2">% START OF INFORMATION ABOUT </span><span class="si">{persons_name}</span><span class="s2">:</span>
<span class="si">{text}</span>
<span class="si">% E</span><span class="s2">ND OF INFORMATION ABOUT </span><span class="si">{persons_name}</span><span class="s2">:</span>

<span class="s2">Please respond with list of a few interview questions based on the topics above</span>

<span class="s2">YOUR RESPONSE:&quot;&quot;&quot;</span>
<span class="n">map_prompt_template</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">map_prompt</span><span class="p">,</span> <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;persons_name&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Then we’ll make our custom combine promopt. This is the set of instructions that we’ll LLM on how to handle the list of questions that is returned in the first step above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">combine_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">You are a helpful AI bot that aids a user in research.</span>
<span class="s2">You will be given a list of potential interview questions that we can ask </span><span class="si">{persons_name}</span><span class="s2">.</span>

<span class="s2">Please consolidate the questions and return a list</span>

<span class="s2">% INTERVIEW QUESTIONS</span>
<span class="si">{text}</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">combine_prompt_template</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">template</span><span class="o">=</span><span class="n">combine_prompt</span><span class="p">,</span> <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;persons_name&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s create our LLM and chain. I’m increasing the color a bit for more creative language. If you notice that your questions have hallucinations in them, turn temperature to 0</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mf">.25</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;gpt-4&#39;</span><span class="p">)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">load_summarize_chain</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span>
                             <span class="n">chain_type</span><span class="o">=</span><span class="s2">&quot;map_reduce&quot;</span><span class="p">,</span>
                             <span class="n">map_prompt</span><span class="o">=</span><span class="n">map_prompt_template</span><span class="p">,</span>
                             <span class="n">combine_prompt</span><span class="o">=</span><span class="n">combine_prompt_template</span><span class="p">,</span>
<span class="c1">#                              verbose=True</span>
                            <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Ok, finally! With all of our data gathered and prompts ready, let’s run our chain</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">chain</span><span class="p">({</span><span class="s2">&quot;input_documents&quot;</span><span class="p">:</span> <span class="n">docs</span><span class="p">,</span> <span class="c1"># The seven docs that were created before</span>
                <span class="s2">&quot;persons_name&quot;</span><span class="p">:</span> <span class="s2">&quot;Elad Gil&quot;</span>
               <span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning: model not found. Using cl100k_base encoding.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span> <span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;output_text&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1. As an investor and advisor to various AI companies, what are some common challenges you&#39;ve observed in the industry, and how do you recommend overcoming them?

2. Can you elaborate on the advantages of bootstrapping for AI startups and share any success stories you&#39;ve come across?

3. What are some key lessons you&#39;ve learned from your experiences in high-profile companies like Twitter, Google, and Color Health that have shaped your approach to investing and advising startups?

4. How do you think AI will continue to shape the job market in the coming years?

5. What motivated you to enter the healthcare space as a co-founder of Color Health, and how do you envision the role of AI in improving healthcare outcomes?

6. Can you share some insights on what sets high growth companies apart from others and the key factors that contribute to their rapid growth?

7. How do you evaluate the defensibility of AI startups when considering investment or advisory opportunities?

8. What excites you the most about the future of AI, and what challenges do you foresee in its development and implementation?

9. Can you share your vision for Color Health and how it aims to revolutionize the healthcare industry?

10. What were the key challenges you faced during the rapid growth of Twitter, and how did you overcome them?

11. What advice would you give to founders looking to build defensibility into their startups from the beginning?

12. Can you share an example of a company that has successfully maintained a user-centric focus and how it has contributed to their success?

13. How do you see the balance between serving customer needs and building defensibility evolving in the future of AI-driven products and services?

14. Can you elaborate on the factors that contribute to your prediction of 2023 being a rough year for mid to late-stage private technology companies and how startups can prepare for these challenges?

15. What do you think are the most promising applications of large language models like GPT in the near future, and how can startups leverage them for growth?

16. How do you see the open versus closed structure playing out in the AI industry, and what implications could it have for startups and established companies in the AI space?

17. How do you think the costs involved in training large language models like GPT-3 and GPT-4 will affect competition and innovation in the AI industry, particularly for startups with limited resources?

18. What do you think are the key factors driving growth in the space and defense technology sector, and what opportunities do you see for startups in this industry?

19. How do you envision the future of defense tech startups, and what challenges do they need to overcome to succeed in this competitive landscape?

20. What lessons can other startups in the defense sector learn from Anduril&#39;s success, and how can they apply these strategies to their own businesses?
</pre></div>
</div>
</div>
</div>
<p>Awesome! Now we have some questions we can iterate on before we chat with the person. You can swap out different sources for different people.</p>
<p>These questions won’t be 100% ‘copy &amp; paste’ ready, but they should serve as a really solid starting point for you to build on top of.</p>
<p>Next, let’s port this code over to a <a class="reference external" href="https://streamlit.io/">Streamlit</a> app so we can share a deployed version easily</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "anukchat/mlguide",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/genai/langchain/projects"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
<div class="section ablog__blog_comments">
   
</div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#levels-of-summarization-novice-to-expert">5 Levels Of Summarization: Novice to Expert</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-1-basic-prompt-summarize-a-couple-sentences">Level 1: Basic Prompt - Summarize a couple sentences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-2-prompt-templates-summarize-a-couple-paragraphs">Level 2: Prompt Templates - Summarize a couple paragraphs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-3-map-reduce-summarize-a-couple-pages-multiple-pages">Level 3: Map Reduce - Summarize a couple pages multiple pages</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-4-best-representation-vectors-summarize-an-entire-book">Level 4: Best Representation Vectors - Summarize an entire book</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#level-5-agents-summarize-an-unknown-amount-of-text">Level 5: Agents - Summarize an unknown amount of text</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-llms-to-summarize-personal-research">Using LLMs To Summarize Personal Research</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pulling-data-from-twitter">Pulling Data From Twitter</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pulling-data-from-websites">Pulling Data From Websites</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pulling-data-from-youtube">Pulling Data From YouTube</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Anukool Chaturvedi
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div class="social-icons">
    <a href="https://twitter.com/chaturanukool" target="_blank"><i class="fab fa-twitter"></i></a>
    <a href="https://linkedin.com/in/anukool-chaturvedi" target="_blank"><i class="fab fa-linkedin"></i></a>
    <a href="https://github.com/anukchat" target="_blank"><i class="fab fa-github"></i></a>
    </p>
</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>