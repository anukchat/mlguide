<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
  <id>https://mlguide.in</id>
  <title>Blog</title>
  <updated>2024-12-22T17:57:41.673744+00:00</updated>
  <link href="https://mlguide.in"/>
  <link href="https://mlguide.in/content/resources/blogs/atom.xml" rel="self"/>
  <generator uri="https://ablog.readthedocs.io/" version="0.11.12">ABlog</generator>
  <entry>
    <id>https://mlguide.in/content/resources/blogs/2024/Decoding%20the%20Byte%20Latent%20Transformer_%20A%20New%20Approach%20to%20Language%20Processing.html</id>
    <title>Byte Latent Transformer: A New Approach to Language Processing</title>
    <updated>2024-12-22T00:00:00+00:00</updated>
    <author>
      <name>Anukool Chaturvedi</name>
    </author>
    <content type="html">&lt;p class="ablog-post-excerpt"&gt;&lt;p&gt;Let’s understand &lt;strong&gt;“Byte Latent Transformer: Patches Scale Better Than Tokens.”&lt;/strong&gt;  This paper introduces a novel approach to handling large language models tokens, potentially offering significant improvements in efficiency and performance. We will explore the core concepts, methodology, and potential implications of this research, drawing insights from the original paper and related discussions.&lt;/p&gt;
&lt;/p&gt;

    &lt;script type="text/x-thebe-config"&gt;
    {
        requestKernel: true,
        binderOptions: {
            repo: "anukchat/mlguide",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/resources"
        },
        predefinedOutput: true
    }
    &lt;/script&gt;
    &lt;script&gt;kernelName = 'python3'&lt;/script&gt;</content>
    <link href="https://mlguide.in/content/resources/blogs/2024/Decoding%20the%20Byte%20Latent%20Transformer_%20A%20New%20Approach%20to%20Language%20Processing.html"/>
    <summary>Let’s understand “Byte Latent Transformer: Patches Scale Better Than Tokens.”  This paper introduces a novel approach to handling large language models tokens, potentially offering significant improvements in efficiency and performance. We will explore the core concepts, methodology, and potential implications of this research, drawing insights from the original paper and related discussions.</summary>
    <category term="AI" label="AI"/>
    <category term="LanguageProcessing" label="Language Processing"/>
    <category term="LargeLanguageModels" label="Large Language Models"/>
    <category term="MachineLearning" label="Machine Learning"/>
    <category term="NLP" label="NLP"/>
    <published>2024-12-22T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://mlguide.in/content/resources/blogs/2024/DeepSeek-VL2_%20A%20Powerful%20Vision-Language%20Model%20for%20Multimodal%20Understanding%20%281%29.html</id>
    <title>DeepSeek-VL2: A Powerful Vision-Language Model for Multimodal Understanding</title>
    <updated>2024-12-18T00:00:00+00:00</updated>
    <author>
      <name>Anukool Chaturvedi</name>
    </author>
    <content type="html">&lt;p class="ablog-post-excerpt"&gt;&lt;p&gt;This blog post dives into the exciting advancements of DeepSeek-VL2, a new series of open-source Vision-Language Models (VLMs).  We’ll explore its architecture, training methodology, and impressive performance across diverse multimodal tasks, including visual question answering, optical character recognition, and document understanding.  The model’s innovative approach to handling high-resolution images and its efficient Mixture-of-Experts (MoE) architecture make it a significant leap forward in the field.&lt;/p&gt;
&lt;/p&gt;

    &lt;script type="text/x-thebe-config"&gt;
    {
        requestKernel: true,
        binderOptions: {
            repo: "anukchat/mlguide",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/resources"
        },
        predefinedOutput: true
    }
    &lt;/script&gt;
    &lt;script&gt;kernelName = 'python3'&lt;/script&gt;</content>
    <link href="https://mlguide.in/content/resources/blogs/2024/DeepSeek-VL2_%20A%20Powerful%20Vision-Language%20Model%20for%20Multimodal%20Understanding%20%281%29.html"/>
    <summary>This blog post dives into the exciting advancements of DeepSeek-VL2, a new series of open-source Vision-Language Models (VLMs).  We’ll explore its architecture, training methodology, and impressive performance across diverse multimodal tasks, including visual question answering, optical character recognition, and document understanding.  The model’s innovative approach to handling high-resolution images and its efficient Mixture-of-Experts (MoE) architecture make it a significant leap forward in the field.</summary>
    <category term="AI" label="AI"/>
    <category term="ComputerVision" label="Computer Vision"/>
    <category term="DeepLearning" label="Deep Learning"/>
    <category term="Mixture-of-Experts" label="Mixture-of-Experts"/>
    <category term="NaturalLanguageProcessing" label="Natural Language Processing"/>
    <category term="Vision-LanguageModels" label="Vision-Language Models"/>
    <published>2024-12-18T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://mlguide.in/content/resources/blogs/2024/Prompt%20tuning.html</id>
    <title>Prompt Tuning</title>
    <updated>2024-04-10T00:00:00+00:00</updated>
    <author>
      <name>Anukool Chaturvedi</name>
    </author>
    <content type="html">&lt;p class="ablog-post-excerpt"&gt;&lt;p&gt;Training large pretrained language models is very time-consuming and compute-intensive. As they continue to grow in size, there is increasing interest in more efficient training methods such as &lt;em&gt;prompting&lt;/em&gt;.&lt;/p&gt;
&lt;/p&gt;

    &lt;script type="text/x-thebe-config"&gt;
    {
        requestKernel: true,
        binderOptions: {
            repo: "anukchat/mlguide",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/resources"
        },
        predefinedOutput: true
    }
    &lt;/script&gt;
    &lt;script&gt;kernelName = 'python3'&lt;/script&gt;</content>
    <link href="https://mlguide.in/content/resources/blogs/2024/Prompt%20tuning.html"/>
    <summary>Training large pretrained language models is very time-consuming and compute-intensive. As they continue to grow in size, there is increasing interest in more efficient training methods such as prompting.</summary>
    <category term="LLM" label="LLM"/>
    <category term="Prompt-Tuning" label="Prompt-Tuning"/>
    <published>2024-04-10T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://mlguide.in/content/resources/blogs/2024/LoRA%20%28Low%20Rank%20Adaptation%20of%20Large%20Language%20Models%29.html</id>
    <title>LoRA (Low Rank Adaptation of Large Language Models)</title>
    <updated>2024-04-10T00:00:00+00:00</updated>
    <author>
      <name>Anukool Chaturvedi</name>
    </author>
    <content type="html">&lt;p class="ablog-post-excerpt"&gt;&lt;p&gt;Before diving into LoRA, it’s essential to grasp the concept of &lt;strong&gt;Matrix Decomposition&lt;/strong&gt;.&lt;/p&gt;
&lt;/p&gt;

    &lt;script type="text/x-thebe-config"&gt;
    {
        requestKernel: true,
        binderOptions: {
            repo: "anukchat/mlguide",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/resources"
        },
        predefinedOutput: true
    }
    &lt;/script&gt;
    &lt;script&gt;kernelName = 'python3'&lt;/script&gt;</content>
    <link href="https://mlguide.in/content/resources/blogs/2024/LoRA%20%28Low%20Rank%20Adaptation%20of%20Large%20Language%20Models%29.html"/>
    <summary>Before diving into LoRA, it’s essential to grasp the concept of Matrix Decomposition.</summary>
    <category term="Fine-Tuning" label="Fine-Tuning"/>
    <category term="LLM" label="LLM"/>
    <category term="LoRA" label="LoRA"/>
    <published>2024-04-10T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://mlguide.in/content/resources/blogs/2024/A%20society%20of%20Generative%20AI%20agents%20%21.html</id>
    <title>A society of Generative AI agents !</title>
    <updated>2023-08-19T00:00:00+00:00</updated>
    <author>
      <name>Anukool Chaturvedi</name>
    </author>
    <content type="html">&lt;p class="ablog-post-excerpt"&gt;&lt;p&gt;Imagine, you visit a place where a group of bots have created a society of their own. They have their own shops, homes, schools and they interact with knowns and unknowns, build relationships, do get-togethers, plan a party or say they create an entire ecosystem of their own just like humans do. It may be hard to imagine but fun to think of.&lt;/p&gt;
&lt;/p&gt;

    &lt;script type="text/x-thebe-config"&gt;
    {
        requestKernel: true,
        binderOptions: {
            repo: "anukchat/mlguide",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/resources"
        },
        predefinedOutput: true
    }
    &lt;/script&gt;
    &lt;script&gt;kernelName = 'python3'&lt;/script&gt;</content>
    <link href="https://mlguide.in/content/resources/blogs/2024/A%20society%20of%20Generative%20AI%20agents%20%21.html"/>
    <summary>Imagine, you visit a place where a group of bots have created a society of their own. They have their own shops, homes, schools and they interact with knowns and unknowns, build relationships, do get-togethers, plan a party or say they create an entire ecosystem of their own just like humans do. It may be hard to imagine but fun to think of.</summary>
    <category term="AI" label="AI"/>
    <category term="GenerativeAI" label="GenerativeAI"/>
    <published>2023-08-19T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://mlguide.in/content/resources/blogs/2024/A%20Journey%20Through%20Time-%20The%20Transformation%20of%20AI%20Development.html</id>
    <title>A Journey Through Time- The Transformation of AI Development</title>
    <updated>2023-03-01T00:00:00+00:00</updated>
    <author>
      <name>Anukool Chaturvedi</name>
    </author>
    <content type="html">&lt;p class="ablog-post-excerpt"&gt;&lt;p&gt;I started studying about Machine Learning in 2016, when I took a famous course by Andrew Ng on Machine Learning. After a lot of breaks in between, I was able to complete it and learnt the basics.&lt;/p&gt;
&lt;/p&gt;

    &lt;script type="text/x-thebe-config"&gt;
    {
        requestKernel: true,
        binderOptions: {
            repo: "anukchat/mlguide",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/resources"
        },
        predefinedOutput: true
    }
    &lt;/script&gt;
    &lt;script&gt;kernelName = 'python3'&lt;/script&gt;</content>
    <link href="https://mlguide.in/content/resources/blogs/2024/A%20Journey%20Through%20Time-%20The%20Transformation%20of%20AI%20Development.html"/>
    <summary>I started studying about Machine Learning in 2016, when I took a famous course by Andrew Ng on Machine Learning. After a lot of breaks in between, I was able to complete it and learnt the basics.</summary>
    <category term="AI" label="AI"/>
    <published>2023-03-01T00:00:00+00:00</published>
  </entry>
</feed>
