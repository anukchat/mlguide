
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Encoder-Decoder Architecture</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/intro.css?v=adbe4504" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=2a9655cd" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-GJG3T4ZRZH"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-GJG3T4ZRZH');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-GJG3T4ZRZH');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/ai/nlp/concepts/007_encoder_decoder';</script>
    <script src="../../../../_static/subscription_overlay.js?v=2e74803e"></script>
    <script src="../../../../_static/landing.js?v=93f722cb"></script>
    <link rel="canonical" href="https://mlguide.in/content/ai/nlp/concepts/007_encoder_decoder.html" />
    <link rel="icon" href="../../../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Attention" href="008_attention.html" />
    <link rel="prev" title="Recurrent Neural Network (RNN)" href="006_language_model_rnn.html" /> 
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" /> 
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../../resources/blogs/atom.xml"
  title="Blog"
/>
  
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/MLGuide_logo_nb.png" class="logo__image only-light" alt=" - Home"/>
    <img src="../../../../_static/MLGuide_logo_nb.png" class="logo__image only-dark pst-js-only" alt=" - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../python/python_toc.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../python/1_installation.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/2_syntax_and_symantics.html">Syntax &amp; Symantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/3_functions_and_modules.html">Functions &amp; Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/4_Object_Oriented.html">Object Oriented Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/5_Exceptions_Handling.html">Exceptions Handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/6_Handling_Files.html">Handling Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/7_Datetime_Operations.html">Datetime Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/8_advanced.html">Advanced Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/conceptual_topics.html">Interpreter vs Compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../statistics/statistics-101.html">Statistics</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../mathematics/mathematics_toc.html">Mathematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../mathematics/linear-algebra_vectors.html">Vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mathematics/linear-algebra_matrices.html">Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mathematics/dissimilarity_measures.html">Similarity measure</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../analytics/intro_analytics.html">Data analytics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../analytics/numpy/numpy_toc.html">Numpy</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/numpy/001_Python_NumPy.html">NumPy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/numpy/Python_Numpy_Exercises_with_hints.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../analytics/pandas/pandas_toc.html">Pandas</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/pandas/001_Python_Pandas_DataFrame.html">Pandas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/pandas/002_Pandas_HowTos.html">How To's</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/pandas/003_Pandas_Exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../analytics/matplotlib/matplotlib_toc.html">Matplotlib</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/matplotlib/001_Python_Matplotlib.html">Matplotlib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/matplotlib/003_Python_Matplotlib_Exercises.html">Exercises</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Introduction_to_ml.html">Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/01_Introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/000_Data_Exploration.html">Exploratory Data Analysis</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/001_Data_Preparation.html">Data Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/002_Regression.html">Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/003_Classification.html">Classfication</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/004_Clustering.html">Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/005_Evaluation.html">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/006_Advanced.html">K-Fold Cross Validation</a></li>


<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/007_Dimensionality_Reduction.html">Dimensionality Reduction</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../neural/neural_toc.html">Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../neural/concepts/001_Introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../neural/concepts/002_Backpropogation.html">Backpropogation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../neural/concepts/003_Activations.html">Activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../neural/concepts/004_Optimization.html">Optimizations</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../neural/concepts/pytorch/pytorch_toc.html">Pytorch</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/00_pytorch_fundamentals.html">Fundamentals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/01_pytorch_workflow.html">Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/02_pytorch_classification.html">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/03_pytorch_computer_vision.html">Computer Vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/04_pytorch_custom_datasets.html">Custom Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/06_pytorch_transfer_learning.html">Transfer Learning</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../nlp_intro.html">Natural Language Processing</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="001_traditional_nlp.html">Word Vectors &amp; Dependency Parsing</a></li>
<li class="toctree-l2"><a class="reference internal" href="002_embeddings.html">Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="003_ngram_cnn.html">N Gram using CNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="004_word2vec.html">Word2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="005_language_model_basic.html">Neural Language Model</a></li>

<li class="toctree-l2"><a class="reference internal" href="006_language_model_rnn.html">Recurrent Neural Network (RNN)</a></li>

<li class="toctree-l2 current active"><a class="current reference internal" href="#">Encoder Decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="008_attention.html">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="009_transformer.html">Transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="010_llm_tasks.html">Language Modelling Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="011_appendix.html">Appendix</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../genai/introduction.html">Generative AI</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../genai/prompt-engineering/intro.html">Prompt Engineering</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/basic_prompting.html">Basic Prompting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/advance_prompts.html">Advanced Prompting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/prompts-applications.html">Prompts Applications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/prompts-adversarial.html">Prompts Adversarial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/prompts-reliability.html">Reliability</a></li>



</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../genai/langchain/intro.html">Langchain</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/langchain/01_LangChain_Fundamentals.html">Langchain Cookbook 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/langchain/02_LangChain_Use_Cases.html">Langchain Cookbook 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/langchain/projects/project_toc.html">Projects</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../genai/RAG/intro.html">RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../genai/agents/intro.html">Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../genai/llm-recipes/intro.html">LLM Recipes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../genai/evaluations/intro.html">Evaluations</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../resources/blogs/blogs_toc.html">Blogs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/courses/courses_toc.html">Courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/books/books_toc.html">Books</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/github/awesome-repos.html">Github</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/readings/articles.html">News</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/readings/papers_toc.html">Research papers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../intro_me.html">About me</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/anukchat/mlguide/main?urlpath=lab/tree/content/ai/nlp/concepts/007_encoder_decoder.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/anukchat/mlguide/blob/main/content/ai/nlp/concepts/007_encoder_decoder.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/content/ai/nlp/concepts/007_encoder_decoder.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Encoder-Decoder Architecture</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-required-packages">Install required packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-data">Prepare data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-sequence-inputs">Generate sequence inputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-encoder-decoder-network">Build Encoder-Decoder Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train">Train</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#translate-text">Translate Text</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                   <section class="tex2jax_ignore mathjax_ignore" id="encoder-decoder-architecture">
<h1>Encoder-Decoder Architecture<a class="headerlink" href="#encoder-decoder-architecture" title="Link to this heading">#</a></h1>
<p><strong><mark>(Machine Translation Example)</mark></strong></p>
<p>In the previous example, we saw the primitive text generation example with RNN, in which <mark>each word is selected only by the previous sequence of words.</mark></p>
<p>But, in most cases, the word should be decided with other information (context) - i.e, conditioned text generation.</p>
<p>For instance, it‚Äôs in question-answering, it should generate text along with the answer (context) for the given question.</p>
<p><strong>Let‚Äôs see the following architecture:</strong></p>
<p>In this architecture, the word is selected by both the sequence of words and context information <code class="docutils literal notranslate"><span class="pre">c</span></code>.<br></p>
<p>For instance, when it generates text for movie review, the conditioned context <code class="docutils literal notranslate"><span class="pre">c</span></code> might be a context about this movie.</p>
<p>Even when it generates the text freely, it might be btter to generate a text depending on a context of genre - such as, ‚Äúcomputer science‚Äù, ‚Äúsports‚Äù, ‚Äúpolitics‚Äù, etc -, and it will then be able to generate more appropriate text depending on the genre (theme).</p>
<p><img alt="RNN with conditioned context" src="../../../../_images/conditioned_context.png" /></p>
<p>The <strong>encoder-decoder framework</strong> is a trainer for text generation with <strong>sequence-to-sequence</strong> conditioned context as follows. (See the following diagram.)</p>
<p>üëâ  For instance, when you want to translate French to English, first it generates a conditioned context <code class="docutils literal notranslate"><span class="pre">c</span></code> from a source sentence (which may have the sequence of length m).<br></p>
<p>üëâ This is called <strong>encoder</strong>, and the encoder summarizes a French sentence as a context vector <code class="docutils literal notranslate"><span class="pre">c</span></code>.<br></p>
<p>üëâ Next it will predict English sentence (which may have the sequence of length n) using the generated context <code class="docutils literal notranslate"><span class="pre">c</span></code>, and this is called <strong>decoder</strong>.<br></p>
<p>As you can see below, the source length (m) and target length (n) might differ in this training.</p>
<p><img alt="encoder-decoder architecture" src="../../../../_images/encoder_decoder.png" /></p>
<p>This <strong>encoder-decoder</strong> architecture can be used in forms of sequence-to-sequence problems, and is used in a lot of scenarios, such as, auto-response (smart reply or question-answering), inflection, image captioning, etc. (In image captioning task, an image input will be encoded as a vector with convolution network.)<br></p>
<p>It can also be used for <strong>generating a vector representation</strong> (in which encoder-decoder is trained to reconstruct the input sentence) or text generation, both which have been seen in the previous examples.<br></p>
<p>A variety of today‚Äôs language tasks depends on encoder-decoder architecture and attention (which will be discussed in the next example).</p>
<p>In this example, I‚Äôll implement simple sequence-to-sequence trainer in machine translation task.</p>
<p>For the purpose of your beginng, here I only use encoder-decoder framework (without attention or other advanced architectures) and I note that the result might not be so good.<br></p>
<p>In the next tutorial, we‚Äôll add more sophisticated architecture ‚Äúattention‚Äù (also, widely used in today‚Äôs NLP) in this encoder-decoder model.</p>
<section id="install-required-packages">
<h2>Install required packages<a class="headerlink" href="#install-required-packages" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span><span class="nv">torch</span><span class="o">==</span><span class="m">2</span>.3.0<span class="w"> </span><span class="nv">torchtext</span><span class="o">==</span><span class="m">0</span>.18.0<span class="w"> </span>--extra-index-url<span class="w"> </span>https://download.pytorch.org/whl/cu114
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>numpy<span class="w"> </span>nltk
</pre></div>
</div>
</div>
</div>
</section>
<section id="prepare-data">
<h2>Prepare data<a class="headerlink" href="#prepare-data" title="Link to this heading">#</a></h2>
<p>In this example, We‚Äôll use Engligh-French dataset by <a class="reference external" href="https://www.manythings.org/anki/">Anki</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget<span class="w"> </span>http://www.manythings.org/anki/fra-eng.zip
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--2023-02-14 01:57:45--  http://www.manythings.org/anki/fra-eng.zip
Resolving www.manythings.org (www.manythings.org)... 173.254.30.110
Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 6720195 (6.4M) [application/zip]
Saving to: ‚Äòfra-eng.zip‚Äô

fra-eng.zip         100%[===================&gt;]   6.41M  11.3MB/s    in 0.6s    

2023-02-14 01:57:45 (11.3 MB/s) - ‚Äòfra-eng.zip‚Äô saved [6720195/6720195]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>unzip<span class="w"> </span>fra-eng.zip<span class="w"> </span>-d<span class="w"> </span>fra-eng
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Archive:  fra-eng.zip
  inflating: fra-eng/_about.txt      
  inflating: fra-eng/fra.txt         
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>head<span class="w"> </span>-n<span class="w"> </span><span class="m">5</span><span class="w"> </span>fra-eng/fra.txt
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Go.	Va !	CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) &amp; #1158250 (Wittydev)
Go.	Marche.	CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) &amp; #8090732 (Micsmithel)
Go.	En route !	CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) &amp; #8267435 (felix63)
Go.	Bouge !	CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) &amp; #9022935 (Micsmithel)
Hi.	Salut !	CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) &amp; #509819 (Aiji)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wc<span class="w"> </span>-l<span class="w"> </span>fra-eng/fra.txt
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>197463 fra-eng/fra.txt
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">pathobj</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;fra-eng/fra.txt&quot;</span><span class="p">)</span>
<span class="n">text_all</span> <span class="o">=</span> <span class="n">pathobj</span><span class="o">.</span><span class="n">read_text</span><span class="p">(</span><span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>
<span class="n">lines</span> <span class="o">=</span> <span class="n">text_all</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_data</span><span class="p">)[:,[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]]</span>
<span class="c1"># print first row</span>
<span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;Va !&#39;, &#39;Go.&#39;], dtype=&#39;&lt;U349&#39;)
</pre></div>
</div>
</div>
</div>
<p>In this training set, text length in the latter part is longer (and includes multiple sentences) than the former part.<br></p>
<p>Therefore We‚Äôll shuffle entire data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;Chantons une chanson\u202f!&#39;, &#39;Let us sing a song.&#39;],
      dtype=&#39;&lt;U349&#39;)
</pre></div>
</div>
</div>
</div>
<p>When data consists of multiple sentences, it converts to a single sentence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">nltk.data</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;punkt&quot;</span><span class="p">)</span>
<span class="n">tokenizer_en</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;tokenizers/punkt/english.pickle&quot;</span><span class="p">)</span>
<span class="n">tokenizer_fr</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;tokenizers/punkt/french.pickle&quot;</span><span class="p">)</span>
<span class="n">fr_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">en_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">:</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="n">tokenizer_fr</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="n">tokenizer_en</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">x2</span><span class="p">):</span>
        <span class="n">fr_list</span> <span class="o">+=</span> <span class="n">x1</span>
        <span class="n">en_list</span> <span class="o">+=</span> <span class="n">x2</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">fr_list</span><span class="p">,</span> <span class="n">en_list</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package punkt to /home/tsmatsuz/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
</pre></div>
</div>
</div>
</div>
<p>To get the better performance (accuracy), we can standarize the input text as follows.</p>
<ul class="simple">
<li><p>Make all words to lowercase in order to reduce words</p></li>
<li><p>Make ‚Äú-‚Äù (hyphen) to space</p></li>
<li><p>Remove all punctuation except ‚Äú ‚Äô ‚Äú (e.g, Ken‚Äôs bag, ces‚Äôt, ‚Ä¶)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">string</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">char</span><span class="o">.</span><span class="n">lower</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">char</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&#39;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">char</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="s2">&quot;¬´¬ª&quot;</span><span class="p">:</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">char</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">char</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="c1"># print first row</span>
<span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;chantons une chanson&#39;, &#39;let us sing a song&#39;], dtype=&#39;&lt;U250&#39;)
</pre></div>
</div>
</div>
</div>
<p>Add <code class="docutils literal notranslate"><span class="pre">&lt;start&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;end&gt;</span></code> tokens in string.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;&lt;start&gt;&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="s2">&quot;&lt;end&gt;&quot;</span><span class="p">]),</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;&lt;start&gt;&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s2">&quot;&lt;end&gt;&quot;</span><span class="p">])]</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_data</span><span class="p">])</span>
<span class="c1"># print first row</span>
<span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;&lt;start&gt; chantons une chanson &lt;end&gt;&#39;,
       &#39;&lt;start&gt; let us sing a song &lt;end&gt;&#39;], dtype=&#39;&lt;U264&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="generate-sequence-inputs">
<h2>Generate sequence inputs<a class="headerlink" href="#generate-sequence-inputs" title="Link to this heading">#</a></h2>
<p>We will generate the sequence of word‚Äôs indices (i.e, tokenize) from text.</p>
<p><img alt="Index vectorize" src="../../../../_images/index_vectorize2.png" /></p>
<p>First we create a list of vocabulary (<code class="docutils literal notranslate"><span class="pre">vocab</span></code>) for both source text (French) and target text (English) respectively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torchtext.data.utils</span> <span class="kn">import</span> <span class="n">get_tokenizer</span>
<span class="kn">from</span> <span class="nn">torchtext.vocab</span> <span class="kn">import</span> <span class="n">build_vocab_from_iterator</span>

<span class="n">max_word</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="c1"># create space-split tokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

<span class="c1"># define tokenization function</span>
<span class="k">def</span> <span class="nf">yield_tokens</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">tokens</span>

<span class="c1"># build vocabulary list for French</span>
<span class="n">vocab_fr</span> <span class="o">=</span> <span class="n">build_vocab_from_iterator</span><span class="p">(</span>
    <span class="n">yield_tokens</span><span class="p">(</span><span class="n">train_data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]),</span>
    <span class="n">specials</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">],</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_word</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">vocab_fr</span><span class="o">.</span><span class="n">set_default_index</span><span class="p">(</span><span class="n">vocab_fr</span><span class="p">[</span><span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">])</span>

<span class="c1"># build vocabulary list for English</span>
<span class="n">vocab_en</span> <span class="o">=</span> <span class="n">build_vocab_from_iterator</span><span class="p">(</span>
    <span class="n">yield_tokens</span><span class="p">(</span><span class="n">train_data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]),</span>
    <span class="n">specials</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">],</span>
    <span class="n">max_tokens</span><span class="o">=</span><span class="n">max_word</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">vocab_en</span><span class="o">.</span><span class="n">set_default_index</span><span class="p">(</span><span class="n">vocab_en</span><span class="p">[</span><span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>The generated token index is <code class="docutils literal notranslate"><span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">...</span> <span class="pre">,</span> <span class="pre">vocab_size</span> <span class="pre">-</span> <span class="pre">1</span></code>.<br></p>
<p>Now we‚Äôll set <code class="docutils literal notranslate"><span class="pre">vocab_size</span></code> as a token id in padded positions for both French and English respctively.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pad_index_fr</span> <span class="o">=</span> <span class="n">vocab_fr</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()</span>
<span class="n">vocab_fr</span><span class="o">.</span><span class="n">append_token</span><span class="p">(</span><span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">)</span>

<span class="n">pad_index_en</span> <span class="o">=</span> <span class="n">vocab_en</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()</span>
<span class="n">vocab_en</span><span class="o">.</span><span class="n">append_token</span><span class="p">(</span><span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Get list for both index-to-word and word-to-index.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">itos_fr</span> <span class="o">=</span> <span class="n">vocab_fr</span><span class="o">.</span><span class="n">get_itos</span><span class="p">()</span>
<span class="n">stoi_fr</span> <span class="o">=</span> <span class="n">vocab_fr</span><span class="o">.</span><span class="n">get_stoi</span><span class="p">()</span>

<span class="n">itos_en</span> <span class="o">=</span> <span class="n">vocab_en</span><span class="o">.</span><span class="n">get_itos</span><span class="p">()</span>
<span class="n">stoi_en</span> <span class="o">=</span> <span class="n">vocab_en</span><span class="o">.</span><span class="n">get_stoi</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># test</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of token index in French (source) is </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vocab_fr</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The padded index in French (source) is </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stoi_fr</span><span class="p">[</span><span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The number of token index in English (target) is </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">vocab_en</span><span class="o">.</span><span class="fm">__len__</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The padded index in English (target) is </span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">stoi_en</span><span class="p">[</span><span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The number of token index in French (source) is 10001.
The padded index in French (source) is 10000.
The number of token index in English (target) is 10001.
The padded index in English (target) is 10000.
</pre></div>
</div>
</div>
</div>
<p>Now we build a collator function, which is used for pre-processing in data loader.</p>
<p>In this collator,</p>
<p>üëâ  First we create a list of word‚Äôs indices for source (French) and target (English) respectively as follows.</p>
<p><code class="docutils literal notranslate"><span class="pre">&lt;start&gt;</span> <span class="pre">this</span> <span class="pre">is</span> <span class="pre">pen</span> <span class="pre">&lt;end&gt;</span></code> ‚Äì&gt; <code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">7,</span> <span class="pre">5,</span> <span class="pre">14,</span> <span class="pre">1]</span></code></p>
<p>üëâ  For target (English) sequence, we separate into features (x) and labels (y).<br>
In this task, we predict the next word in target (English) sequence using the current word‚Äôs sequence (English) and the encoded context of source (French).<br></p>
<p>üëâ  We then separate target sequence into the sequence iteself (x) and the following label (y).</p>
<p><u>before</u> :</p>
<p><code class="docutils literal notranslate"><span class="pre">[2,</span> <span class="pre">7,</span> <span class="pre">5,</span> <span class="pre">14,</span> <span class="pre">1]</span></code></p>
<p><u>after</u> :</p>
<p><code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">:</span> <span class="pre">[2,</span> <span class="pre">7,</span> <span class="pre">5,</span> <span class="pre">14,</span> <span class="pre">1]</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">:</span> <span class="pre">[7,</span> <span class="pre">5,</span> <span class="pre">14,</span> <span class="pre">1,</span> <span class="pre">-100]</span></code></p>
<blockquote>
<div><p>Note : Here havewe  set -100 as an unknown label id, because PyTorch cross-entropy function <strong>torch.nn.functional.cross_entropy()</strong>) has a property <code class="docutils literal notranslate"><span class="pre">ignore_index</span></code> which default value is -100.</p>
</div></blockquote>
<p>üëâ Finally we pad the inputs (for both source and target) as follows.<br>
The padded index in features is <code class="docutils literal notranslate"><span class="pre">pad_index</span></code> and the padded index in label is -100. (See above note.)</p>
<p><code class="docutils literal notranslate"><span class="pre">x</span> <span class="pre">:</span> <span class="pre">[2,</span> <span class="pre">7,</span> <span class="pre">5,</span> <span class="pre">14,</span> <span class="pre">1,</span> <span class="pre">N,</span> <span class="pre">...</span> <span class="pre">,</span> <span class="pre">N]</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">:</span> <span class="pre">[7,</span> <span class="pre">5,</span> <span class="pre">14,</span> <span class="pre">1,</span> <span class="pre">-100,</span> <span class="pre">-100,</span> <span class="pre">...</span> <span class="pre">,</span> <span class="pre">-100]</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">seq_len_fr</span> <span class="o">=</span> <span class="mi">45</span>
<span class="n">seq_len_en</span> <span class="o">=</span> <span class="mi">38</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">collate_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
    <span class="n">label_list</span><span class="p">,</span> <span class="n">feature_source_list</span><span class="p">,</span> <span class="n">feature_target_list</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">text_fr</span><span class="p">,</span> <span class="n">text_en</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
        <span class="c1"># (1) tokenize to a list of word&#39;s indices</span>
        <span class="n">tokens_fr</span> <span class="o">=</span> <span class="n">vocab_fr</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_fr</span><span class="p">))</span>
        <span class="n">tokens_en</span> <span class="o">=</span> <span class="n">vocab_en</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text_en</span><span class="p">))</span>
        <span class="c1"># (2) separate into features and labels in target tokens (English)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">tokens_en</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">)</span>
        <span class="c1"># (3) limit length to seq_len and pad sequence</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">seq_len_en</span><span class="p">]</span>
        <span class="n">tokens_fr</span> <span class="o">=</span> <span class="n">tokens_fr</span><span class="p">[:</span><span class="n">seq_len_fr</span><span class="p">]</span>
        <span class="n">tokens_en</span> <span class="o">=</span> <span class="n">tokens_en</span><span class="p">[:</span><span class="n">seq_len_en</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">+=</span> <span class="p">[</span><span class="o">-</span><span class="mi">100</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">seq_len_en</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="n">tokens_fr</span> <span class="o">+=</span> <span class="p">[</span><span class="n">pad_index_fr</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">seq_len_fr</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens_fr</span><span class="p">))</span>
        <span class="n">tokens_en</span> <span class="o">+=</span> <span class="p">[</span><span class="n">pad_index_en</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">seq_len_en</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens_en</span><span class="p">))</span>
        <span class="c1"># add to list</span>
        <span class="n">label_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">feature_source_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokens_fr</span><span class="p">)</span>
        <span class="n">feature_target_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokens_en</span><span class="p">)</span>
    <span class="c1"># convert to tensor</span>
    <span class="n">label_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">label_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">feature_source_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">feature_source_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">feature_target_list</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">feature_target_list</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">label_list</span><span class="p">,</span> <span class="n">feature_source_list</span><span class="p">,</span> <span class="n">feature_target_list</span>

<span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train_data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_batch</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># test</span>
<span class="k">for</span> <span class="n">labels</span><span class="p">,</span> <span class="n">sources</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
    <span class="k">break</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;label shape in batch : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;feature source shape in batch : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sources</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;feature target shape in batch : </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">targets</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;***** label sample *****&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;***** features (source) sample *****&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sources</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;***** features (target) sample *****&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">targets</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>label shape in batch : torch.Size([64, 38])
feature source shape in batch : torch.Size([64, 45])
feature target shape in batch : torch.Size([64, 38])
***** label sample *****
tensor([  84,   95,  583, 1489,  343,  159,    1, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,
        -100, -100], device=&#39;cuda:0&#39;)
***** features (source) sample *****
tensor([    2,     3,    76,    77,  4616,    11,   437,  3470,   563,     1,
        10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,
        10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,
        10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,
        10000, 10000, 10000, 10000, 10000], device=&#39;cuda:0&#39;)
***** features (target) sample *****
tensor([    2,    84,    95,   583,  1489,   343,   159,     1, 10000, 10000,
        10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,
        10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000,
        10000, 10000, 10000, 10000, 10000, 10000, 10000, 10000],
       device=&#39;cuda:0&#39;)
</pre></div>
</div>
</div>
</div>
</section>
<section id="build-encoder-decoder-network">
<h2>Build Encoder-Decoder Network<a class="headerlink" href="#build-encoder-decoder-network" title="Link to this heading">#</a></h2>
<p>Now we build a model with encoder-decoder architecture. The brief outline of this architecture is as follows. :</p>
<ul class="simple">
<li><p>The context is generated by using the entire source sequence (French) in encoder.</p></li>
<li><p>The encoder‚Äôs context is then concatenated with the words of current target‚Äôs sequence (English) and passed into RNN layer in decoder.</p></li>
<li><p>RNN outputs (not only final output, but in all units in sequence) is passed into linear (FCNet) layer and generate the logits of next words.</p></li>
<li><p>Calculate loss between predicted next words and the true values of next words, and then proceed to optimize neural networks.</p></li>
</ul>
<p><img alt="the trainer architecture of machine translation" src="../../../../_images/machine_translation.png" /></p>
<p>First, we build encoder model.<br></p>
<p>In this example, only the last output of RNN (GRU) is required in encoder model, because we need a single context in each sequence.</p>
<p><img alt="final output in encoder" src="../../../../_images/encoder_final.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">rnn_units</span> <span class="o">=</span> <span class="mi">1024</span>

<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">rnn_units</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span> <span class="o">=</span> <span class="n">padding_idx</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">embedding_dim</span><span class="p">,</span>
            <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">rnn_units</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># embedding</span>
        <span class="c1">#   --&gt; (batch_size, seq_len, embedding_dim)</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="c1"># build &quot;lengths&quot; property to pack inputs (see previous example)</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># pack inputs for RNN (see previous example)</span>
        <span class="n">packed_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span>
            <span class="n">outs</span><span class="p">,</span>
            <span class="n">lengths</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># apply RNN</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">packed_inputs</span><span class="p">)</span>
        <span class="c1"># (1, batch_size, rnn_units) --&gt; (batch_size, rnn_units)</span>
        <span class="n">final_state</span> <span class="o">=</span> <span class="n">final_state</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># return results</span>
        <span class="k">return</span> <span class="n">final_state</span>

<span class="n">enc_model</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_fr</span><span class="o">.</span><span class="fm">__len__</span><span class="p">(),</span>
    <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
    <span class="n">rnn_units</span><span class="o">=</span><span class="n">rnn_units</span><span class="p">,</span>
    <span class="n">padding_idx</span><span class="o">=</span><span class="n">pad_index_fr</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Next we build decoder model.</p>
<p>The decoder receives encoder‚Äôs final output, and this is used in all units in target‚Äôs sequence.</p>
<p>In each unit, encoder‚Äôs final output (context) is concatenated with word‚Äôs embedding vectors in current target (English).<br></p>
<p>The concatenated vector is then passed into RNN. The output of RNN is then passed into linear (fully-connected network, FCNet) and it generates the next word‚Äôs logits.</p>
<p><img alt="the trainer architecture of machine translation" src="../../../../_images/machine_translation.png" /></p>
<p>Same as previous examples, RNN inputs are packed, because appropriate steps in each sequence should be processed.</p>
<div class="alert alert-info">
<p><strong>Note:</strong> In encoder-decoder architecture, there exist a variation to set encoder‚Äôs final state as decoder‚Äôs initial state.<br></p>
<p>In this example, we don‚Äôt set initial state (i.e, set zero state as initial state) in decoder.</p>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">rnn_units</span><span class="p">,</span> <span class="n">padding_idx</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">=</span><span class="mi">1024</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span> <span class="o">=</span> <span class="n">padding_idx</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span>
            <span class="n">vocab_size</span><span class="p">,</span>
            <span class="n">embedding_dim</span><span class="p">,</span>
            <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="n">embedding_dim</span> <span class="o">+</span> <span class="n">rnn_units</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">rnn_units</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">rnn_units</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classify</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_final_state</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># embedding</span>
        <span class="c1">#   --&gt; (batch_size, seq_len, embedding_dim)</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="c1"># convert the shape of enc_outputs :</span>
        <span class="c1"># (batch_size, rnn_units) --&gt; (batch_size, 1, rnn_units)</span>
        <span class="n">enc_outputs</span> <span class="o">=</span> <span class="n">enc_outputs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># (batch_size, rnn_units) --&gt; (batch_size, seq_len, rnn_units)</span>
        <span class="n">enc_outputs</span> <span class="o">=</span> <span class="n">enc_outputs</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># concat encoder&#39;s output</span>
        <span class="c1">#   --&gt; (batch_size, seq_len, embedding_dim + rnn_units)</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">outs</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># build &quot;lengths&quot; property to pack inputs (see above)</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">padding_idx</span><span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># pack inputs for RNN</span>
        <span class="n">packed_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span>
            <span class="n">outs</span><span class="p">,</span>
            <span class="n">lengths</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">enforce_sorted</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># apply RNN</span>
        <span class="k">if</span> <span class="n">states</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">packed_outs</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">packed_inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">packed_outs</span><span class="p">,</span> <span class="n">final_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">packed_inputs</span><span class="p">,</span> <span class="n">states</span><span class="p">)</span>
        <span class="c1"># unpack results</span>
        <span class="c1">#   --&gt; (batch_size, seq_len, rnn_units)</span>
        <span class="n">outs</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span>
            <span class="n">packed_outs</span><span class="p">,</span>
            <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">total_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># apply feed-forward (hidden)</span>
        <span class="c1">#   --&gt; (batch_size, seq_len, hidden_dim)</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">(</span><span class="n">outs</span><span class="p">)</span>
        <span class="n">outs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">outs</span><span class="p">)</span>
        <span class="c1"># apply feed-forward to classify</span>
        <span class="c1">#   --&gt; (batch_size, seq_len, vocab_size)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classify</span><span class="p">(</span><span class="n">outs</span><span class="p">)</span>
        <span class="c1"># return results</span>
        <span class="k">if</span> <span class="n">return_final_state</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">logits</span><span class="p">,</span> <span class="n">final_state</span>  <span class="c1"># This is used in prediction</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">logits</span>               <span class="c1"># This is used in training</span>

<span class="n">dec_model</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_en</span><span class="o">.</span><span class="fm">__len__</span><span class="p">(),</span>
    <span class="n">seq_len</span><span class="o">=</span><span class="n">seq_len_en</span><span class="p">,</span>
    <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">,</span>
    <span class="n">rnn_units</span><span class="o">=</span><span class="n">rnn_units</span><span class="p">,</span>
    <span class="n">padding_idx</span><span class="o">=</span><span class="n">pad_index_en</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train">
<h2>Train<a class="headerlink" href="#train" title="Link to this heading">#</a></h2>
<p>Now we put it all together and run training.</p>
<p>The loss on label id=-100 is ignored in <code class="docutils literal notranslate"><span class="pre">cross_entropy()</span></code> function. The padded position and the end of sequence will then be ignored in optimization.</p>
<div class="alert alert-info">
<p><strong>Note :</strong> Because the default value of  <code class="docutils literal notranslate"><span class="pre">ignore_index</span></code> property in <code class="docutils literal notranslate"><span class="pre">cross_entropy()</span></code> function is -100. (You can change this default value.)</p>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">all_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">enc_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">dec_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">all_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">labels</span><span class="p">,</span> <span class="n">sources</span><span class="p">,</span> <span class="n">targets</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
        <span class="c1"># optimize</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">enc_outputs</span> <span class="o">=</span> <span class="n">enc_model</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">dec_model</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="c1"># calculate accuracy</span>
        <span class="n">pred_labels</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">num_correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred_labels</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">num_total</span> <span class="o">=</span> <span class="p">(</span><span class="n">labels</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">num_correct</span> <span class="o">/</span> <span class="n">num_total</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{}</span><span class="s2"> - loss: </span><span class="si">{:2.4f}</span><span class="s2"> - accuracy: </span><span class="si">{:2.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">accuracy</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1 - loss: 2.7009 - accuracy: 0.6364
Epoch 2 - loss: 1.6154 - accuracy: 0.7273
Epoch 3 - loss: 0.7325 - accuracy: 0.8125
Epoch 4 - loss: 0.1153 - accuracy: 1.0000
Epoch 5 - loss: 0.4040 - accuracy: 0.9231
</pre></div>
</div>
</div>
</div>
</section>
<section id="translate-text">
<h2>Translate Text<a class="headerlink" href="#translate-text" title="Link to this heading">#</a></h2>
<p>Now <mark>translate French text to English text with trained model</mark>. (All these sentences are not in training set.)</p>
<p>Here we simply translate several brief sentences, but the metrics to evaluate text-generation task will not be so easy. (Because simply checking an exact match to a reference text is not optimal.)<br></p>
<p>To evaluate the trained model, use some common metrics available in text generation, such as, <strong>BLEU</strong> or <strong>ROUGE</strong>.</p>
<blockquote>
<div><p>Note : Here we use greedy search and this will sometimes lead to wrong sequence.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">end_index_en</span> <span class="o">=</span> <span class="n">stoi_en</span><span class="p">[</span><span class="s2">&quot;&lt;end&gt;&quot;</span><span class="p">]</span>
<span class="n">max_output</span> <span class="o">=</span> <span class="mi">128</span>

<span class="k">def</span> <span class="nf">translate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="c1"># preprocess inputs</span>
    <span class="n">text_fr</span> <span class="o">=</span> <span class="n">sentence</span>
    <span class="n">text_fr</span> <span class="o">=</span> <span class="n">text_fr</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">text_fr</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;&lt;start&gt;&quot;</span><span class="p">,</span> <span class="n">text_fr</span><span class="p">,</span> <span class="s2">&quot;&lt;end&gt;&quot;</span><span class="p">])</span>
    <span class="n">text_en</span> <span class="o">=</span> <span class="s2">&quot;&lt;start&gt;&quot;</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">tokens_fr</span><span class="p">,</span> <span class="n">tokens_en</span> <span class="o">=</span> <span class="n">collate_batch</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="n">text_fr</span><span class="p">],</span> <span class="p">[</span><span class="n">text_en</span><span class="p">])))</span>

    <span class="c1"># process encoder</span>
    <span class="n">enc_outputs</span> <span class="o">=</span> <span class="n">enc_model</span><span class="p">(</span><span class="n">tokens_fr</span><span class="p">)</span>

    <span class="c1"># process decoder</span>
    <span class="n">states</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">for</span> <span class="n">loop</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_output</span><span class="p">):</span>
        <span class="n">logits</span><span class="p">,</span> <span class="n">states</span> <span class="o">=</span> <span class="n">dec_model</span><span class="p">(</span>
            <span class="n">tokens_en</span><span class="p">,</span>
            <span class="n">enc_outputs</span><span class="p">,</span>
            <span class="n">states</span><span class="o">=</span><span class="n">states</span><span class="p">,</span>
            <span class="n">return_final_state</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">pred_idx_en</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
        <span class="n">next_word_en</span> <span class="o">=</span> <span class="n">itos_en</span><span class="p">[</span><span class="n">pred_idx_en</span><span class="p">]</span>
        <span class="n">text_en</span> <span class="o">+=</span> <span class="s2">&quot; &quot;</span>
        <span class="n">text_en</span> <span class="o">+=</span> <span class="n">next_word_en</span>
        <span class="k">if</span> <span class="n">pred_idx_en</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">end_index_en</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">tokens_en</span> <span class="o">=</span> <span class="n">collate_batch</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="s2">&quot;&lt;end&gt;&quot;</span><span class="p">],</span> <span class="p">[</span><span class="n">next_word_en</span><span class="p">])))</span>
    <span class="k">return</span> <span class="n">text_en</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">translate</span><span class="p">(</span><span class="s2">&quot;j&#39;aime la guitare&quot;</span><span class="p">))</span> <span class="c1"># i like guitar</span>
<span class="nb">print</span><span class="p">(</span><span class="n">translate</span><span class="p">(</span><span class="s2">&quot;il vit au japon&quot;</span><span class="p">))</span> <span class="c1"># he lives in Japan</span>
<span class="nb">print</span><span class="p">(</span><span class="n">translate</span><span class="p">(</span><span class="s2">&quot;ce stylo est utilis√© par lui&quot;</span><span class="p">))</span> <span class="c1"># this pen is used by him</span>
<span class="nb">print</span><span class="p">(</span><span class="n">translate</span><span class="p">(</span><span class="s2">&quot;c&#39;est ma chanson pr√©f√©r√©e&quot;</span><span class="p">))</span> <span class="c1"># that&#39;s my favorite song</span>
<span class="nb">print</span><span class="p">(</span><span class="n">translate</span><span class="p">(</span><span class="s2">&quot;il conduit une voiture et va √† new york&quot;</span><span class="p">))</span> <span class="c1"># he drives a car and goes to new york</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;start&gt; i like the guitar &lt;end&gt;
&lt;start&gt; he lives in japan &lt;end&gt;
&lt;start&gt; this book is close to him &lt;end&gt;
&lt;start&gt; this is my favorite song &lt;end&gt;
&lt;start&gt; he drives a family and he will return to a new car &lt;end&gt;
</pre></div>
</div>
</div>
</div>
<p>In this vanilla encoder-decoder architecture, the source (French) is encoded into a single context, and it will then be hard to manipulate the long context.<br></p>
<p>In the next exercise, we will refine architecture to tackle this weak points.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "anukchat/mlguide",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/ai/nlp/concepts"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
<div class="section ablog__blog_comments">
   
</div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="006_language_model_rnn.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Recurrent Neural Network (RNN)</p>
      </div>
    </a>
    <a class="right-next"
       href="008_attention.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Attention</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-required-packages">Install required packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-data">Prepare data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-sequence-inputs">Generate sequence inputs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-encoder-decoder-network">Build Encoder-Decoder Network</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train">Train</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#translate-text">Translate Text</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Anukool Chaturvedi
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  <div class="social-icons">
    <a href="https://twitter.com/chaturanukool" target="_blank"><i class="fab fa-twitter"></i></a>
    <a href="https://linkedin.com/in/anukool-chaturvedi" target="_blank"><i class="fab fa-linkedin"></i></a>
    <a href="https://github.com/anukchat" target="_blank"><i class="fab fa-github"></i></a>
    </p>
</div>

</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>