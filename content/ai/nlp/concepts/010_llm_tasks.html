
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Language Model Tasks</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/intro.css?v=50f34f2b" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/ai/nlp/concepts/010_llm_tasks';</script>
    <script src="../../../../_static/subscription_overlay.js?v=2e74803e"></script>
    <script src="https://apis.google.com/js/platform.js"></script>
    <script src="../../../../_static/landing.js?v=93f722cb"></script>
    <link rel="canonical" href="https://mlguide.in/content/ai/nlp/concepts/010_llm_tasks.html" />
    <link rel="icon" href="../../../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Appendix" href="011_appendix.html" />
    <link rel="prev" title="Transformer" href="009_transformer.html" /> 
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" /> 
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../../resources/blogs/atom.xml"
  title="Blog"
/>
  
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/MLGuide_logo_nb.png" class="logo__image only-light" alt=" - Home"/>
    <img src="../../../../_static/MLGuide_logo_nb.png" class="logo__image only-dark pst-js-only" alt=" - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../python/python_toc.html">Python</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../python/1_installation.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/2_syntax_and_symantics.html">Syntax &amp; Symantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/3_functions_and_modules.html">Functions &amp; Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/4_Object_Oriented.html">Object Oriented Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/5_Exceptions_Handling.html">Exceptions Handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/6_Handling_Files.html">Handling Files</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/7_Datetime_Operations.html">Datetime Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/8_advanced.html">Advanced Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/conceptual_topics.html">Interpreter vs Compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../python/exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../statistics/statistics-101.html">Statistics</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../mathematics/mathematics_toc.html">Mathematics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../mathematics/linear-algebra_vectors.html">Vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mathematics/linear-algebra_matrices.html">Matrices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../mathematics/dissimilarity_measures.html">Similarity measure</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../analytics/intro_analytics.html">Data analytics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../analytics/numpy/numpy_toc.html">Numpy</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/numpy/001_Python_NumPy.html">NumPy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/numpy/Python_Numpy_Exercises_with_hints.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../analytics/pandas/pandas_toc.html">Pandas</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/pandas/001_Python_Pandas_DataFrame.html">Pandas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/pandas/002_Pandas_HowTos.html">How To's</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/pandas/003_Pandas_Exercises.html">Exercises</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../analytics/matplotlib/matplotlib_toc.html">Matplotlib</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/matplotlib/001_Python_Matplotlib.html">Matplotlib</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../analytics/matplotlib/003_Python_Matplotlib_Exercises.html">Exercises</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Introduction_to_ml.html">Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/01_Introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/000_Data_Exploration.html">Exploratory Data Analysis</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/001_Data_Preparation.html">Data Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/002_Regression.html">Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/003_Classification.html">Classfication</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/004_Clustering.html">Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/005_Evaluation.html">Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/006_Advanced.html">K-Fold Cross Validation</a></li>


<li class="toctree-l2"><a class="reference internal" href="../../classicml/concepts/007_Dimensionality_Reduction.html">Dimensionality Reduction</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../neural/neural_toc.html">Neural Networks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../neural/concepts/001_Introduction.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../neural/concepts/002_Backpropogation.html">Backpropogation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../neural/concepts/003_Activations.html">Activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../neural/concepts/004_Optimization.html">Optimizations</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../neural/concepts/pytorch/pytorch_toc.html">Pytorch</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/00_pytorch_fundamentals.html">Fundamentals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/01_pytorch_workflow.html">Workflow</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/02_pytorch_classification.html">Classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/03_pytorch_computer_vision.html">Computer Vision</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/04_pytorch_custom_datasets.html">Custom Datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../neural/concepts/pytorch/06_pytorch_transfer_learning.html">Transfer Learning</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../nlp_intro.html">Natural Language Processing</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="001_traditional_nlp.html">Word Vectors &amp; Dependency Parsing</a></li>
<li class="toctree-l2"><a class="reference internal" href="002_embeddings.html">Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="003_ngram_cnn.html">N Gram using CNN</a></li>
<li class="toctree-l2"><a class="reference internal" href="004_word2vec.html">Word2Vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="005_language_model_basic.html">Neural Language Model</a></li>

<li class="toctree-l2"><a class="reference internal" href="006_language_model_rnn.html">Recurrent Neural Network (RNN)</a></li>

<li class="toctree-l2"><a class="reference internal" href="007_encoder_decoder.html">Encoder Decoder</a></li>
<li class="toctree-l2"><a class="reference internal" href="008_attention.html">Attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="009_transformer.html">Transformer</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Language Modelling Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="011_appendix.html">Appendix</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../genai/introduction.html">Generative AI</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../genai/prompt-engineering/intro.html">Prompt Engineering</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/basic_prompting.html">Basic Prompting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/advance_prompts.html">Advanced Prompting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/prompts-applications.html">Prompts Applications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/prompts-adversarial.html">Prompts Adversarial</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/prompt-engineering/prompts-reliability.html">Reliability</a></li>



</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../genai/langchain/intro.html">Langchain</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/langchain/01_LangChain_Fundamentals.html">Langchain Cookbook 1</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/langchain/02_LangChain_Use_Cases.html">Langchain Cookbook 2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../genai/langchain/projects/project_toc.html">Projects</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../genai/RAG/intro.html">RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../genai/agents/intro.html">Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../genai/llm-recipes/intro.html">LLM Recipes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../genai/evaluations/intro.html">Evaluations</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../resources/blogs/blogs_toc.html">Blogs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/books/books_toc.html">Books</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/courses/courses_toc.html">Courses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/github/awesome-repos.html">Trending GitHub repos</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/readings/articles.html">News</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../resources/readings/papers_toc.html">Research papers</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../intro_me.html">About me</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../../_sources/content/ai/nlp/concepts/010_llm_tasks.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Language Model Tasks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#question-answering">Question Answering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-based-question-answering">LSTM-Based Question Answering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bert-based-question-answering">BERT-based Question Answering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#open-domain-question-answering">Open-Domain Question Answering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#natural-language-generation">Natural Language Generation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decoding-from-nlg-models">Decoding From NLG Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-nlg-models">Training NLG Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-nlg-systems">Evaluating NLG Systems</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ethical-considerations">Ethical Considerations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coreference-resolution">Coreference Resolution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-references">Types of References</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-coreference-models">Types of Coreference Models</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                   <section class="tex2jax_ignore mathjax_ignore" id="language-model-tasks">
<h1>Language Model Tasks<a class="headerlink" href="#language-model-tasks" title="Link to this heading">#</a></h1>
<p><strong>Reference</strong>: <a class="reference external" href="https://www.youtube.com/watch?v=rmVRLeJRkl4">Stanford CS224N</a></p>
<hr class="docutils" />
<section id="question-answering">
<h2>Question Answering<a class="headerlink" href="#question-answering" title="Link to this heading">#</a></h2>
<p>What is question answering? The goal of <strong>question answering</strong> is to build a system that automatically answers questions posed by humans in a <em>natural language</em>.</p>
<p>Question answering can be done on structured or unstructured text. Today we focus on unstructured text. To understand and answer a question, a system must be able to comprehend the reading.</p>
<p>Reading comprehension and question-answering has applications in google search, personal assistants, and general intelligence in large.</p>
<p><strong>Stanford question answering dataset (SQuAD)</strong> is a large question-answering dataset with 100k annotated triplets of (passage, question, answer). Answers are short segments of text in the passage. It’s the most popular question-answering dataset. Evaluation is done with an <strong>exact match (EM)</strong> which can be 0 or 1 and <strong>F1</strong> which is partial credit. Estimated human performance on SQuAD is EM = 82.3, F1 = 91.2.</p>
<p><img alt="image.png" src="../../../../_images/squad_eval.PNG" /> <br>
<em>Figure 1. SQuAD evaluation.</em></p>
<p>The problem formulation for SQuAD is shown below:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Input: ~ C = (c_1, c_2, ..., c_N), Q = (q_1, q_2, ..., q_M), c_i, q_i \in V; N \approx 100, M \approx 15\\
Output: 1 \le start \le end \le N\\
\end{split}\]</div>
<p>Approaches to this problem come in 2 forms: <strong>LSTM-based</strong> methods and <strong>BERT models</strong>.</p>
<section id="lstm-based-question-answering">
<h3>LSTM-Based Question Answering<a class="headerlink" href="#lstm-based-question-answering" title="Link to this heading">#</a></h3>
<p>The <strong>Bidirectional Attention Flow (BiDAF)</strong> model is from a paper in 2017 that tackles SQuAD.</p>
<p><img alt="image.png" src="../../../../_images/bidaf.PNG" /> <br>
<em>Figure 2. BiDAF Architecture.</em></p>
<p>It concatenates word embeddings and character embeddings to be fed into 2 bidirectional LSTMs which produce contextual embeddings for both context and query. Character-level embeddings are generated through a 1D CNN. Word-level embeddings are from GloVe.</p>
<p>The next set of layers is for the attention between the query statement and the context passage and vice versa.</p>
<p><img alt="image.png" src="../../../../_images/context2query.PNG" /> <br>
<em>Figure 3. Context to query attention.</em></p>
<p><img alt="image.png" src="../../../../_images/query2context.PNG" /> <br>
<em>Figure 4. Query to Context attention.</em></p>
<p>The output from the attention flow layers gets passed to more bi-directional LSTMs. These are finally passed into an output layer.</p>
<p>BiDAF achieves 77.3 F1 on SQuAD.</p>
</section>
<section id="bert-based-question-answering">
<h3>BERT-based Question Answering<a class="headerlink" href="#bert-based-question-answering" title="Link to this heading">#</a></h3>
<p>BERT-based models outperform BiDAF by a ton! They leverage the BERT framework as the name suggests.</p>
<p>BiDAF and BERT models are fundamentally similar. They both model interactions between question and passage. BERT uses self-attention to model interactions within the passage, the question, passage and queestion, and question and passage.</p>
<p><img alt="image.png" src="../../../../_images/bidaf_vs_bert_squad.PNG" /> <br>
<em>Figure 5. BiDAF vs BERT variants on SQuAD.</em></p>
<p>Even by exceeding human performance, these models aren’t perfect. They easily lose to adversarial examples.</p>
</section>
<section id="open-domain-question-answering">
<h3>Open-Domain Question Answering<a class="headerlink" href="#open-domain-question-answering" title="Link to this heading">#</a></h3>
<p>In Open-Domain question-answering, we don’t assume a given passage, but rather, a huge corpus of documents.</p>
<p>In this field, we use a <strong>retriever-reader framework</strong>.</p>
<p><img alt="image.png" src="../../../../_images/reader_retriever.PNG" /> <br>
<em>Figure 6. Retriever-reader framework.</em></p>
<p>The problem is formulated like this:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Input: \mathcal{D} = D_1, D_2, ..., D_N ~ and ~ Q\\
Output: an ~ answer ~ string ~ A\\
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
Retriever: f(\mathcal{D}, Q) \rightarrow P_1, ..., P_K \hspace{1em} (K ~ is ~ pre-defined)\\
Reader: g(Q, \{P_1, ..., P_K\}) \rightarrow A
\end{split}\]</div>
<p>We use a TF-IDF information-retrieval sparse model for retrieving passages. And we use a neural network for reading comprehension from the passages.</p>
<p>Both the retriever and reader can be trained jointly with BERT models for both. Recent work has shown that sometimes you don’t even need the retriever! T5, for example, can simply be trained to <em>generate</em> the answers. Other work has shown that a reader model may not even be needed! Phrases and text can be densely encoded and nearest neighbors search can be ran.</p>
</section>
</section>
<section id="natural-language-generation">
<h2>Natural Language Generation<a class="headerlink" href="#natural-language-generation" title="Link to this heading">#</a></h2>
<p><strong>Natural Language Geenration (NLG)</strong> is a sub-field of NLP. This field focuses on building a system that can automatically produce coherentt and useful written or spoken text.</p>
<p>We see applications of NLG in dialogue systems like Siri and Alexa and chatbots. NLG systems also are great at summarizing text, generating text from data, describing visual images.</p>
<p>An autoregressive text generation model will generate a new token/word based on previous words.</p>
<div class="math notranslate nohighlight">
\[
P(y_t~|~ \{y_{&lt; t}\}) = \frac{exp(S_w)}{\sum_{w' \in V} exp(S_{w'})}
\]</div>
<section id="decoding-from-nlg-models">
<h3>Decoding From NLG Models<a class="headerlink" href="#decoding-from-nlg-models" title="Link to this heading">#</a></h3>
<p>A <strong>decoding algorithm</strong> takes this probability distribution and converts them to a token. More formally, it is defined mathematically below.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\hat{y}_t = g(P(y_t~|~ \{y_{&lt; t}\})) \hspace{1em} (Eq.~1)\\
\end{split}\]</div>
<p>There are many different decoding algorithms. The most popular is the <strong>greedy method</strong> that simply takes the argmax of the distribution of tokens. There is also <strong>beam search</strong> which is still greedy but has a wider array of candidates.</p>
<p>Many decoding algorithms generate repetitive text which we don’t want. Ways to counteract this is to have a heuristic telling the model to not repeat <span class="math notranslate nohighlight">\(n\)</span>-grams.</p>
<p><strong>Top-k sampling</strong> samples tokens randomly from the top-k most likely. This kind of helps with the repetition problem. This is good but is a little problematic because the higher <span class="math notranslate nohighlight">\(k\)</span> is, the more diverse the outputs are, the higher chance they have to make less sense. With a lower <span class="math notranslate nohighlight">\(k\)</span>, outputs would be repetitive.</p>
<p><strong>Top-p (nucleus) sampling</strong> samples all tokens in the top <span class="math notranslate nohighlight">\(p\)</span> cumulative probability mass. This ameliorates the hard threshold of selecting a <span class="math notranslate nohighlight">\(k\)</span> because depending on the sentence and the previous sequence of tokens, the distribution of the next token changes.</p>
<p>Another concept that can improve these decoding algorithms is <strong>temperature <span class="math notranslate nohighlight">\(\tau\)</span></strong>.</p>
<div class="math notranslate nohighlight">
\[
P(y_t = w) = \frac{exp(S_w / \tau)}{\sum_{w' \in V} exp(S_{w'} / \tau)}
\]</div>
<p>This temperature allows you to controls the distribution of the tokens. A temperature &gt; 1 makes for more diverse outputs (more uniform). A temperature &lt; 1 spikes the distribution and makes for less diverse outputs (more repetitive). This concept helps all the previous decoding methods we described but not argmax sampling!</p>
<p>There are other more complex methods for decoding.</p>
<p><img alt="image.png" src="../../../../_images/rebalance_decoding.PNG" /> <br>
<em>Figure 1. Re-balancing distribution of tokens based off of a cached database.</em></p>
<p>In Figure 1, from what I understand, the authors rebalance the distribution of tokens at time step <span class="math notranslate nohighlight">\(t\)</span> with an induced distribution <span class="math notranslate nohighlight">\(P_{phrase}\)</span>. I would think this not only betters the repetition problem (in certain contexts) but also lends itself to more human-like/understandable text.</p>
<p><img alt="image.png" src="../../../../_images/backprop_based_discriminator.PNG" /> <br>
<em>Figure 2. Backpropagation-based distribution re-balancing.</em></p>
<p>In Figure 2, the authors there introduced an <em>attribute model</em> which will enforce certain characteristics in how your NLG model will learn. It can enforce behavior like sentiment.</p>
<p>Instead of re-balancing a distribution, we can also change the ranking of tokens with a <strong>ranking algorithm</strong>. We can define a score to approximate the quality of sequences and re-rank tokens by this score.</p>
</section>
<section id="training-nlg-models">
<h3>Training NLG Models<a class="headerlink" href="#training-nlg-models" title="Link to this heading">#</a></h3>
<p>NLG models are trained with <strong>teacher forcing</strong>. That is, when the text generator (transformer decoder in the transformer case) learns to generate text, it will accept its own previously generated tokens as a sequence. Instead, it will be given the ground truth tokens. This helps it learn faster.</p>
<p>Training with teacher forcing leads to <strong>exposure bias</strong> because during inference time, the model won’t have access to these gold standard context tokens.</p>
<p>We train NLG models by maximizing the likelihood of the next word, but humans don’t talk like this! Training via maximizing likelihood leads to repetitive text. Some work has introduced another loss term deemed the <strong>unlikelihood</strong> loss. Which will force the model to lower the likelihood of previously-seen tokens. This limits repetition and increases diversity!</p>
<p><img alt="image.png" src="../../../../_images/exposure_bias_solutions.PNG" /> <br>
<img alt="image-2.png" src="../../../../_images/exposure_bias_solutions_1.PNG" /> <br></p>
<p><em>Figure 3. Some exposure bias solutions.</em></p>
</section>
<section id="evaluating-nlg-systems">
<h3>Evaluating NLG Systems<a class="headerlink" href="#evaluating-nlg-systems" title="Link to this heading">#</a></h3>
<p>There are 3 types of evaluation metrics:</p>
<ul class="simple">
<li><p><strong>content overlap metrics</strong></p></li>
<li><p><strong>model-based metrics</strong></p></li>
<li><p><strong>human evaluation</strong></p></li>
</ul>
<p>BLEU is an example of a content overlap metric. These types of metrics are not ideal for machine translation (language may have many synonyms, not a single way to generate something correct). There are also <strong>semantic overlap metrics</strong> which evaluate semantics or meaning rather than just matching tokens. Some popular semantic overlap metrics include PYRAMID, SPICE, and SPIDER.</p>
<p>Model-based metrics use learned representations of words and sentences to compute a semantic similarity between generated and reference text. Some popular model-based metrics include vector similarity, Word Mover’s distance, BERTSCORE, Sentence Movers Similarity, and BLEURT.</p>
<p>Human evaluation is expensive, but this type of evaluation can be more tailored towards a task (and be more accurate). Humans also are prone to errors.</p>
</section>
<section id="ethical-considerations">
<h3>Ethical Considerations<a class="headerlink" href="#ethical-considerations" title="Link to this heading">#</a></h3>
<p>Microsoft’s twitter chatbot AI <a class="reference external" href="http://tay.ai">tay.ai</a> went from “humans are super cool” to harmful and negative statements in just a day. Language models learn biases in our culture from the text it is trained on.</p>
<p>These models need safeguards and need to be carefully managed and considered before deployment.</p>
</section>
</section>
<section id="coreference-resolution">
<h2>Coreference Resolution<a class="headerlink" href="#coreference-resolution" title="Link to this heading">#</a></h2>
<p><strong>Coreference Resolution</strong> is the task of identifying all mentions that refer to the same entity in the world. For example: Vincent ate the spaghetti. He thought it was great. Here “he” refers to Vincent and “it” refers to spaghetti.</p>
<p>This sub-field of NLP is one of many cornerstones to teaching a machine how to understand and produce useful language. It has applications in full text understanding, machine translation.</p>
<p>Coreference Resolution is traditionally done in 2 parts:</p>
<ul class="simple">
<li><p>detect the mentions (easy)</p></li>
<li><p>cluster the mentions (hard)</p></li>
</ul>
<p>We can define a <strong>mention</strong> as a span of text referring to some entity like the following:</p>
<ul class="simple">
<li><p>pronouns</p></li>
<li><p>named entities</p>
<ul>
<li><p>Paris</p></li>
</ul>
</li>
<li><p>noun phrases</p></li>
</ul>
<p>For pronouns, we can use a part-of-speech tagger, NER systems for named entities, and a parser for noun phrases.</p>
<section id="types-of-references">
<h3>Types of References<a class="headerlink" href="#types-of-references" title="Link to this heading">#</a></h3>
<p>Specifically, <strong>Coreference</strong> is when 2 mentions refer to the same entity. A related linguistic concept is an <strong>anaphora</strong> where a term (<em>anaphor</em>) refers to another term (antecedent). For example,</p>
<p>Barack Obama said he would sign the bill.</p>
<p>Here “he” references “Barack Obama”.</p>
<p><img alt="image.png" src="../../../../_images/coref_vs_anaphora.PNG" /> <br>
<em>Figure 1. Coreference vs Anaphora.</em></p>
<p>So cases where we detect an anaphora <em>may</em> be a coreference. However not all anaphoras are coreferences.</p>
<p>Every dancer twisted her knee.</p>
<p>No dancer twisted her knee.</p>
<p>Both of these sentences contain anaphoric relationships but “her knee” doesn’t refer to a specific entity. These are called <strong>bridging anaphoras</strong>. If an anaphora is also a coreference, then it is called a <strong>pronominal anaphora</strong>. <strong>Cataphoras</strong> are the exact opposite of anaphoras. The reference follows after the antecedent.</p>
<p>Coreference and anaphora are just 2 examples of how we build a <strong>discourse model</strong> of whatever we are listening or reading.</p>
</section>
<section id="types-of-coreference-models">
<h3>Types of Coreference Models<a class="headerlink" href="#types-of-coreference-models" title="Link to this heading">#</a></h3>
<p>There are 4 types of coreference models:</p>
<ul class="simple">
<li><p>rule-based (pronominal anaphora resolution)</p></li>
<li><p>mention-pair</p></li>
<li><p>mention-ranking</p></li>
<li><p>clustering (skipped in this lecture)</p></li>
</ul>
<p><strong>Hobbs’ naive algorithm</strong> is a rule-based model for tackling pronominal anaphora resolution.</p>
<p><img alt="image.png" src="../../../../_images/hobbs_naive.PNG" /> <br>
<img alt="image-2.png" src="../../../../_images/hobbs_rules.PNG" /> <br>
<em>Figure 2. Hobbs’ naive algorithm.</em></p>
<p>There is an additional problem/nuance! Pronominal coreference can also be <strong>knowledge-based</strong>.</p>
<p>She poured water from the pitcher into the cup until it was full.</p>
<p>She poured water from the pitcher into the cup until it was empty.</p>
<p>Here “it” can mean the pitcher or the cup. The reason you know it is because of world knowledge! These are referred to as <strong>Winograd Schemas</strong>.</p>
<p>Mention-pair is another method for coreference resolution. We can train a binary classifier that assigns every pair of mentions a probability of being coreferent.</p>
<p><img alt="image.png" src="../../../../_images/mention_pair.PNG" /> <br>
<em>Figure 3. Mention-pair approach.</em></p>
<p>We can train it kind of contrastively by maximizing the likelihood of actual coreferences to have a predicted probability of 1 while negative pairs would be minimized.</p>
<p>This approach explodes with more mentions as you can tell!</p>
<p>Mention-ranking, from what I understand, is an extension of that by adding an NA token in the front so not all mentions need to associated with another mention. Mention-ranking is characterized by assigning each mention its highest scoring candidate antecedent according to the model.</p>
<p>This “model” can be a statistical classifier, neural network or more complex methods.</p>
<p><img alt="image.png" src="../../../../_images/mention_pair_nn.PNG" /> <br>
<em>Figure 4. Neural network for coreference resolution.</em></p>
<p><img alt="image.png" src="../../../../_images/mention_pair_bilstm.PNG" /> <br>
<em>Figure 5. BiLSTM for coreference resolution.</em></p>
<p>Modern day SOTA methods use BERT!</p>
<p><img alt="image.png" src="../../../../_images/comparisons_coref_res.PNG" /> <br>
<em>Figure 6. Different method performances.</em></p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/ai/nlp/concepts"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>
<div class="section ablog__blog_comments">
   
</div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="009_transformer.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Transformer</p>
      </div>
    </a>
    <a class="right-next"
       href="011_appendix.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Appendix</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#question-answering">Question Answering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lstm-based-question-answering">LSTM-Based Question Answering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bert-based-question-answering">BERT-based Question Answering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#open-domain-question-answering">Open-Domain Question Answering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#natural-language-generation">Natural Language Generation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decoding-from-nlg-models">Decoding From NLG Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-nlg-models">Training NLG Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluating-nlg-systems">Evaluating NLG Systems</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ethical-considerations">Ethical Considerations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#coreference-resolution">Coreference Resolution</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-references">Types of References</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-coreference-models">Types of Coreference Models</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Anukool Chaturvedi
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>